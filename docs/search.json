[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "통알못을 위한 기초통계 2",
    "section": "",
    "text": "서문\nSaientia a Dei입니다. 2019년 1월부터 YouTube 통알못을 위한 기초통계 강의를 시작하게 되어 2021년부터는 이를 책으로 만드는 작업을 시작했습니다. 개인사정으로 인해 몇 년간 지지부진 하던 상황에서 마음을 다잡고 책을 썼습니다. 여러가지 옵션을 고민하던 중에 micro-web-book을 결정하였습니다. micro-web-book이란 개념도 제가 혼자 만든 것인데, 소책자 크기로 하여 주제별로 쪼개어 제공하는 것을 의미 합니다. 여기에는 나름 여러가지의 고민이 있었습니다. 이미 꽤 많은 양의 통계강의를 YouTube로 만들은데 반해 이 모든 내용을 한 번에 책으로 쓰기는 것이 제 개인적인 역량을 봐서는 단 기간에 어렵다고 판단한 것도 한가지 이유입니다. 그러나, 이보다 더 중요한 이유는 제 서재의 수많은 통계책을 보면서 고민한 것이 있습니다. 저도 미국에서부터 꽤 많은 통계책을 사서 읽었지만 수 백 페이지 정도의 두꺼운 통계책 중에 처음부터 끝까지 모두 다 읽은 경우는 정말 한 두 권 정도에 불과 했습니다. 저의 경우는 특정 부분이 필요 해서 구매한 통계책이 대부분이었습니다. 그래서 저도 통알못을 위한 책을 쓰는 마당에 보다 미래 지향적이고 실용적인 방법을 찾아야겠다는 마음을 먹었습니다. 운 좋게도 어느 출판사에서 책을 출판하자는 제안이 있기는 했지만, 돈 보다는 지식의 공유가 더 중요하다는 생각에 오픈 소스 북으로 책을 내기로 했고 이를 주제별로 쪼개서 시리즈물로 책을 쓰는 것이 좋겠다고 생각했습니다. 그러니 독자분들께서도 필요한 주제별로 micro-web-book을 읽으실 것을 권해드립니다. 두껍고 무겁기만한 종이책이 읽혀지지도 않은 채로 서재 어딘가에 몇 년간 방치되는 것 보다는 이 편이 낫다고 생각됩니다. 필요에 따라서 스마트폰이나 패드를 이용하셔서 출퇴근 시간 혹은 자투리 시간에 읽으실 수 있을 것입니다.\n2권부터는 보다 본격적인 통계 방법론에 대한 소개입니다. 1장은 이원배치 분산분석 (Two-way ANOVA)로 시작하여 2장의 Contrast, 3장의 반복측정 분산분석과 마지막 4장의 3원배치 분산분석으로 마무리됩니다. 특별한 목적이 있지 않는 한 보통은 이원배치 분산분석 정도까지가 대부분 공부하게 되실 거라고 생각됩니다. 제가 특별히 그 이상을 유투브에서 강의 했던 이유는 그다지 많은 책들이 나머지 부분들에 대해서 다소 소홀하다는 생각이 들어서 였습니다.\n여전히 통계 전공자도 아닌 제가 강의를 하고 책을 쓰는 것이 부담스럽습니다. 이 책을 보시는 통계학과 교수님들과 전공자 분들에게 다시 한 번 너그러운 양해를 부탁드립니다. 정통 통계학적인 측면에서 보자면 오류가 있을 수 있습니다. 이 책의 내용에 대한 비판은 제가 감당할 부분이나 부드럽고 건설적인 비평을 부탁드립니다.\n이 책은 YouTube의 통통튜브 (통알못을 위한 통계튜브)의 온라인 비디오 강의를 보다 자세하게 풀어 말로 적은 것입니다. 처음 보시는 분들은 이 책을 한번 가볍게 보시고 난 후 각 절의 마지막에 있는 YouTube 바로가기 링크를 통해 비디오로 한 번 보시고 다시 본문을 읽어 보실 것을 권해드립니다. 한 번에 모든 것을 이해할 수 있다면 좋겠으나 반복 학습이 보다 효과적이라고 생각합니다. 유튜브 주소는 아래와 같습니다. 네이버 블로그에도 링크가 되어 있으니 편하신 플랫폼으로 비디오를 보시면 될 것 같습니다. 더불어 실습에 사용될 모든 샘플파일은 GitHub에 저장되어 있으니 자유롭게 다운로드 받아 사용하시기 바랍니다.\n마지막으로 제가 유투브를 통해 공개한 통통튜브의 내용이나 이 책의 내용을 무단으로 사용하지 마시길 부탁드립니다. 무료로 공개한 내용이지만 저의 노력과 오랜 기간의 아이디어가 담긴 것들입니다. 가끔 이런 무료공개 정보는 저작권이 없다고 생각하시고 심지어 제 강의 내용을 상업적 용도로 사용하시는 분들이 있는데 이는 분명한 저작물권의 침해입니다. 혼자 공부하기 위해 자료를 만들어 혼자서 보는 것은 누가 뭐라 할 수 없으나 정리된 내용을 인터넷으로 공개하거나 상업적인 목적으로 사용 혹은 배포하는 것은 분명 문제의 소지가 있음을 알려드립니다. 법적인 책임을 가리는 일이 없기를 바랍니다.\nYoutube 채널\n네이버 블로그\n샘플파일 다운로드\n부족한 제 강의와 책에 관심을 가져주시는 모든 분들께 감사의 말씀 올립니다."
  },
  {
    "objectID": "chapter1.html#이원배치-분산분석이란",
    "href": "chapter1.html#이원배치-분산분석이란",
    "title": "1  이원배치 분산분석 (Two-way ANOVA)",
    "section": "1.1 이원배치 분산분석이란?",
    "text": "1.1 이원배치 분산분석이란?\n\n1.1.1 이원배치 분산분석은 무엇이 다를까?\n앞서 우리는 일원배치 분산분석을 공부했습니다. 앞에서 실습했던 내용을 정리해 보면 Figure 1.1 에 잘 나타나 있습니다.\n\n\n\nFigure 1.1: 일원배치 분산분석\n\n\nFigure 1.1 을 보면 종속변수는 연속변수 형태인 Total charges였습니다. 그리고 하나의 독립변수인 Payment method는 총 4 개의 그룹을 가지고 있었습니다. 우리는 이 4 개의 그룹에 따라서 종속변수인 Total charges가 변화가 있는지 없는지 살펴보았습니다. 이를 위해 일원배치 분산분석 (One-way ANOVA)를 했던 것이지요. 이제 우리는 여기에 한 개의 독립변수를 추가하여 이원배치 분산분석 (Two-way ANOVA)를 할 것입니다. 가장 마지막에 실습할 내용은 Figure 1.2 에 나타나 있습니다.\n\n\n\nFigure 1.2: 이원배치 분산분석\n\n\nFigure 1.2 에서 보이듯 우리는 추가적으로 한 개의 독립변수를 더 사용할 것입니다. 바로 Contract라는 변수입니다. 이 변수가 의미하는 것은 고객이 계약한 서비스 기간입니다. 여기에는 세 가지의 그룹이 있습니다. Month-to-month, One-year, Two-year입니다. 이제 우리는 앞서 Payment method의 4 개의 그룹에 따라 종속변수인 Total charges가 같은지 다른지 보았던 거세 더하여 이제는 Contract의 3 개의 그룹에 따라서 종속변수가 어떻게 변하는지 또한 보고자 하는 것입니다.\n\n\n1.1.2 Main Effect (주효과) & Interaction Effect(상호작용)\n이처럼 두 개의 독립변수의 종속변수에 대한 직접적인 영향력을 주효과 혹은 Main effect라고 부릅니다. 두 개의 독립변수가 있으니 당연히 Two-way ANOVA에는 두 개의 Main effect가 있다고 생각할 수 있겠습니다. 그러나 독립변수가 한 개 늘어나면서 일원배치 분산분석에는 없었던 것이 하나 늘어납니다. 바로 Interaction effect (상호작용/교호작용)입니다. Interaction effect가 무엇일까요? 정의는 일단 이렇습니다. 한 독립변수의 Main effect가 다른 독립변수의 level (=group)에 따라 원래의 linear relationship이 non-linear 하게 변하는 경우를 말합니다.\n이게 무슨 뜻일까요?\n먼저, Linear relationship 부터 알아봅시다. Linear relationship이란 우리말로 선형관계라고 합니다. 여기서 선형은 직선을 의미 합니다. 독립변수와 종속변수의 관계가 (직)선의 관계라고 이미 전제하는 겁니다. 사실 이미 우리가 배웠던 t-test나 One-way ANOVA에도 (직)선 관계는 이미 전제되어 있었습니다. 다만, 여러분들의 이해를 돕기 위해 굳이 이야기 하지 않았을 뿐입니다. 기본적으로 앞으로 우리가 하게 될 거의 모든 통계적 분석은 대부분 선형관계를 전제 한다고 보면 됩니다.\n이제 우리는 선형관계를 이용해 Interaction effect를 그림을 이용해서 이해할 것입니다. 다음에 등장하는 그림들을 잘 보고 설명을 따라 오기 바랍니다. 이해를 위해 One-way ANOVA에서 시작할 것입니다. 한 개의 독립변수가 있고 쉽게 이해하기 위해 한 개의 독립변수는 단 두 개의 그룹(레벨)을 가지고 있다고 가정해 봅시다. 그리고 우리는 두 그룹의 평균값을 아래의 표로 표현할 수 있습니다.\n\n\nTable 1.1: 일원배치 분산분석 예\n\n\n구분\nX1의 Level 1\nX1의 Level 2\nX1 Total\n\n\nMean\n5\n10\n7.5\n\n\n\n\nTable 1.1 을 그림으로 그려보면 Figure 1.3 입니다. 그림에서 보듯이 두 그룹의 평균값은 점으로 표현되어 있고 그 사이를 점선으로 이어 놓았습니다. 이렇게 한 이유는 두 그룹에 의한 종속변수의 값의 변화가 직선의 관계에 있음을 보여드리기 위함입니다. 이제 여기에 독립변수를 한 개 더 추가하겠습니다. 역시 쉬운 이해를 위해 단 두 개의 그룹만을 가진 독립변수입니다.\n\n\n\nFigure 1.3: 일원배치 분산분석 예\n\n\n\n\nTable 1.2: 이원배치 분산분석 예\n\n\n구분\nX1의 Level 1\nX1의 Level 2\nMean\n\n\nX2의 Level 1\n5\n10\n7.5\n\n\nX2의 Level 2\n3\n8\n5.5\n\n\nMean\n4\n9\n6.5\n\n\n\n\nTable 1.2 를 그림으로 나타내면 아래 Figure 1.4 로 표현할 수 있습니다.\n\n\n\nFigure 1.4: 이원배치 분산분석 예\n\n\nFigure 1.4 에서 보는 것처럼 추가된 두 번째 독립변수 X2 역시 종속변수와 직선의 관계를 유지하고 있음을 알 수 있습니다. 뒤에서 설명하겠지만 결론적으로 X1과 종속변수의 선형관계가 추가된 독립변수 X2에 의해서 변화하지 않았고, 또한 X2와 종속변수 사이의 선형관계가 X1이라는 다른 독립변수에 의해 변화하지 않았으므로 이 경우에는 Interaction이 없는 것입니다. 이제 여러 가지 그림을 보면서 다양한 Interaction effect를 이해해 보도록 합시다. 가장 중요한 것은 Interaction effect라는 것이 한 가지 형태가 아니고 매우 다양한 형태로 존재한다는 것입니다.\n\n\n\n\n\n\n\n(a) 예제1\n\n\n\n\n\n\n\n(b) 예제2\n\n\n\n\nFigure 1.5: Interaction 예제 1 & 2\n\n\nFigure 1.5 (a) 을 보면 X1의 Main effect는 없으며, X2의 Main effect도 없고, Interaction도 없습니다. Figure 1.5 (b) 는 X1의 Main effect는 유의하나 X2의 Main effect는 없고 Interaction도 없습니다. 이해가 되시나요? 위의 두 그림에서 X1의 Main effect가 하나는 있고 하나는 없는 이유는 Figure 1.5 (a) 에서는 X1의 Level 1에 해당하는 두 점의 평균값과 X1의 Level 2에 해당하는 두 점의 평균값이 같기 때문입니다. 그러나 Figure 1.5 (b) 에서는 X1의 Level 1에 해당하는 두 점의 평균값과 X1의 Level 2에 해당하는 두 점의 평균값이 확연하게 다릅니다. 따라서 유의한 차이가 있다고 볼 수 있습니다. X2의 Main effect가 위의 두 예제에서 모두 없는 이유는 X2의 Level 1에 해당하는 점선으로 연결된 두 점의 평균값과 X2의 Level 2에 해당하는 점선으로 연결된 두 점의 평균값이 동일하기 때문입니다. Figure 1.5 (a) 에서는 그냥 수평의 직선에 해당하는 종속변수의 값에 둘 다가 매칭 될 것이고, Figure 1.5 (b) 에서는 점선의 중간 정도가 두 점의 평균값이 될 텐데, 이 평균값이 Level 1이나 Level2나 동일할 것이기 때문입니다.\n그럼 이제 또 다른 예제를 살펴보겠습니다.\n\n\n\n\n\n\n\n(a) 예제3\n\n\n\n\n\n\n\n(b) 예제4\n\n\n\n\nFigure 1.6: Interaction 예제 3 & 4\n\n\nFigure 1.6 (a) 의 경우에는 X1의 Main effect는 없으며, X2의 Main effect는 유의하고, Interaction은 없습니다. Figure 1.6 (b) 는 X1의 Main effect는 유의하고 X2의 Main effect도 유의하고 Interaction은 없습니다. 이제 Main effect가 어떤 것은 유의하고 어떤 것은 유의하지 않은지 구분이 좀 되시나요? 더불어 여태 위에서 본 4 가지의 경우 모두 Interaction이 없었습니다. 이제 Interaction이 있는 경우를 좀 살펴보도록 하겠습니다.\n\n\n\n\n\n\n\n(a) 예제5\n\n\n\n\n\n\n\n(b) 예제6\n\n\n\n\nFigure 1.7: Interaction 예제 5 & 6\n\n\nFigure 1.7 (a) 는 매우 재미있는 경우입니다. X1의 Main effect는 없으며, X2의 Main effect도 없으나, Interaction은 유의한 경우입니다. Figure 1.7 (b) 은 X1의 Main effect는 없고 X2의 Main effect는 유의하고 Interaction은 있는 경우입니다. Figure 1.7 (a) 에 대해서 설명해 보자면, X1의 Level 1에 해당하는 두 점의 평균값은 두 점의 중간 정도일 것이고 X1의 Level 2에 해당하는 두 점의 평균값 역시 두 점의 중간정도로 같기 때문입니다. X2의 Level 1에 해당하는 점선으로 연결된 두 점의 평균값은 두 선이 교차하는 지점 정도가 될 것이고, X2의 Level 2에 해당하는 점선으로 연결된 두 점의 평균값 역시 두 선이 교차하는 지점이 될 것이므로 두 그룹의 평균값은 동일하기 때문입니다. 그러나 두 선은 분명히 X자로 교차하고 있고 이는 명확히 한 독립변수의 종속변수에 대한 효과가 다른 독립변수에 의해 변화된 것이므로 Interaction은 있는 것입니다.\nFigure 1.7 (b) 는 다소 애매한 경우인데, 사실 X1의 Main effect가 없다고 보는 것이 제 의견에는 합리적이라 생각되지만, 보는 사람의 입장에 따라서는 X1의 Main effect가 약간은 있다고 주장할 수도 있습니다. 어쨌든 이와는 별개로 X2의 Main effect는 분명하게 유의하고 Interaction도 유의하다 즉 있다고 보는 것이 맞는다고 판단됩니다. 왜냐하면 두 직선은 분명히 평행하지는 않기 때문에 상호간에 Interaction이 있다고 볼 수 있습니다.\n\n\n\n\n\n\n\n(a) 예제7\n\n\n\n\n\n\n\n(b) 예제8\n\n\n\n\nFigure 1.8: Interaction 예제 7 & 8\n\n\nFigure 1.8 (a) 의 경우는 X1의 Main effect는 유의하고 X2의 Main effect는 없습니다. 왜냐하면 X2의 Level 1에 해당하는 점선으로 연결된 두 점의 평균값은 두 선이 교차하는 지점 정도가 될 것이고, X2의 Level 2에 해당하는 점선으로 연결된 두 점의 평균값 역시 두 선이 교차하는 지점이 될 것이므로 두 그룹의 평균값은 동일하기 때문입니다. 그러나 Interaction은 분명하게 있습니다. 왜냐하면 두 직선이 교차하기 때문입니다. 이렇게 교차하는 모양이 되면 무조건 Interaction이 있다고 보시면 됩니다.\nFigure 1.8 (b) 의 경우에는 X1과 X2의 Main effect가 둘 다 유의하고 Interaction도 유의합니다. 한 직선은 X축에 평행하게 되어 있으나 한 직선은 그렇지 않기 때문입니다. 이제 Interaction이라는 것이 좀 이해가 되시나요? 마지막으로 두 개의 예제를 더 보겠습니다.\n\n\n\n\n\n\n\n(a) 예제9\n\n\n\n\n\n\n\n(b) 예제10\n\n\n\n\nFigure 1.9: Interaction 예제 9 & 10\n\n\nFigure 1.9 (a) 와 Figure 1.9 (b) 은 모두 X1의 Main effect는 없지만 X2의 Main effect는 유의하고 당연히 Interaction도 유의합니다. 이 경우 왜 X1의 Main effect가 없느냐고 하시는 분도 있을 텐데요. X1의 Level 1에 해당하는 두 점의 평균값은 두 점의 중간 정도일 텐데 X1의 Level 2에 해당하는 두 점의 평균값 역시 두 점의 중간정도로 같기 때문입니다. 다만 Figure 1.9 (a) 에서는 X1의 Level 1의 두 점이 일치하는 것이고, Figure 1.9 (b) 에서는 X1의 Level 2에서 두 점이 일치하는 거일 뿐 X1의 두 그룹의 평균값은 동일하게 됩니다. 반면에, X2의 Level 1에 해당하는 점선으로 연결된 두 점의 평균값은 두 선의 중간 지점 정도가 될 것이고, X2의 Level 2에 해당하는 점선으로 연결된 두 점의 평균값 역시 두 선의 중간 지점이 될 것이므로 두 그룹의 평균값은 확연히 달라지기 때문입니다. 물론 둘 다 Interaction은 분명히 유의할 것입니다.\n결론적으로, Interaction 이란, 한 독립변수의 종속변수에 대한 영향관계가 다른 독립변수의 level(=group)에 따라 변할 경우, 우리는 이를 Interaction effect (상호작용/교호작용)이 있다고 합니다. 이 Interaction은 연구/조사에 있어서 매우 중요합니다. 왜냐하면, 기존에 이러한 Interaction이 존재한다는 것이 알려지지 않았다면 두 독립변수를 이용하여 다양한 결과를 예측할 수 있는 가능하기 때문입니다. 기존에 원인을 알 수 없었던 종속변수의 결과(반응)에 대해 그 원인을 알 수 있는 기본이 될 수 있습니다.\n이제 우리는 이원배치 분산분석의 기본과 일원배치 분산분석과 다른 점을 알아보았습니다. 이제 조금 더 Two-way ANOVA에 대해 알아보도록 하겠습니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter1.html#이원배치-분산분석-전에-알아야-할-것들",
    "href": "chapter1.html#이원배치-분산분석-전에-알아야-할-것들",
    "title": "1  이원배치 분산분석 (Two-way ANOVA)",
    "section": "1.2 이원배치 분산분석 전에 알아야 할 것들",
    "text": "1.2 이원배치 분산분석 전에 알아야 할 것들\n\n1.2.1 ANOVA가 t-test를 대신한다면?\n다소 뜬금없는 질문이긴 한데 만약 그룹이 2 개인 경우 t-test가 아닌 일원배치 분산분석을 하면 어떻게 될까요? 가능하긴 할까요? 물론 가능합니다. 3 개 이상의 그룹의 평균값을 비교할 수 있는 ANOVA인데 겨우 두 개의 그룹의 평균값을 비교하지 못할 리가 없죠. 궁금하시다면 앞서 t-test에서 사용했던 샘플 데이터로 ANOVA를 해보길 바랍니다. 직접 해보는 것만큼 좋은 공부가 없습니다. 다만 한 가지 재미있는 사실은 결과를 t-test와 비교해 보면 \\({t-value}^2 = \\text{F-value}\\)가 되는 것을 아실 수 있을 겁니다.\n\n\n1.2.2 이원배치 분산분석의 F-value\n앞에서 공부한 일원배치 분산분석을 다시 떠 올려 봅시다. 분산분석은 F-value를 구하는 것이라고 했고 이 F-value는 Between Variance와 Within Variance의 비율이었습니다. 일원배치 분산분석은 사실상 Main effect가 한 개이기 때문에 F-value가 한 개 필요했습니다. 그렇다면 이원배치 분산분석에서는 F-value가 몇 개 필요할까요? 잠시 생각해 봅시다.\n일단 이원배치 분산분석은 독립변수가 두 개이므로 Main effect가 두 개 이기 때문에 F-value가 두 개 필요합니다. 여기에 더해서 우리는 앞서 Interaction effect가 이원배치 분산분석에 추가되었다는 사실을 배웠습니다. 그러므로 Interaction effect가 유의한지 아닌지 알기 위해서는 Interaction effect를 검정하기 위한 F-value가 한 개 더 필요합니다. 그러므로 이원배치 분산분석에서는 총 3 개의 F-value가 필요합니다. Figure 1.10 에서 볼 수 있듯이 2 개의 Main effect용 F-value와 한 개의 Interaction effect용 F-value가 필요합니다.\n\n\n\nFigure 1.10: 이원배치 분산분석의 F-value\n\n\n그렇다면 총 몇 개의 Between Variance와 Within Variance가 필요할까요?\n먼저 Between Variance는 당연히 총 3 개가 필요합니다. 왜냐하면 우리의 관심사는 언제나 F-value의 분자 부분인 Between Variance이기 때문입니다. 이 Between Variance가 충분히 크다는 것은 적어도 한 그룹의 평균값이 전체 평균값에서 멀어져 있다는 의미가 되기 때문이지요. 문제는 그렇다면 몇 개의 Within Variance가 필요한지 입니다. 깊게 생각해 보지 않는다면 보통 여기서 3 개의 Within Variance가 필요하다고 답하게 됩니다. 그런데 다시 한 번 생각해 봅시다. 일단 F-value에서 Within Variance의 역할이 무엇인가요? 계속 반복하듯이 Between Variance만으로는 이게 큰지 작은지 알 수 없기 때문에 비교대상이 필요하고 그 비교대상으로 Within Variance를 사용한다고 했습니다. 그렇다면 이 Within Variance는 일종의 비교대상이자 기준이 되는 것입니다. 만약 기준이 세 개의 Between Variance에 대해서 다르게 적용된다면 이게 올바른 것일까요? 아닙니다. 기준은 한 개면 충분하고 그래야만 합니다. 그래야 기준으로서 객관성을 유지할 수 있고 기준이 되는 비교대상으로서 역할을 할 수 있는 것이기 때문입니다. 따라서 Between Variance 3개와 Within Variance 1 개가 필요합니다. 총 4 개의 Variance가 있으면 이원배치 분산분석을 할 수 있는 것입니다.\n\\[F-value_{Main \\; effect1} = \\frac{Between \\; Variance_{Main \\; effect1}}{Within \\; Variance} = \\frac{\\frac{SS_{Main \\; effect1}}{df_1\\;of\\;Main\\;effect1}}{\\frac{SS_{Within}}{df_2\\;of\\;Within\\;Variance}}\\]\n\\[F-value_{Main \\; effect2} = \\frac{Between \\; Variance_{Main \\; effect2}}{Within \\; Variance} = \\frac{\\frac{SS_{Main \\; effect2}}{df_1\\;of\\;Main\\;effect2}}{\\frac{SS_{Within}}{df_2\\;of\\;Within\\;Variance}}\\]\n\\[F-value_{Interaction \\; effect} = \\frac{Between \\; Variance_{Interaction \\; effect}}{Within \\; Variance} = \\frac{\\frac{SS_{Interaction \\; effect}}{df_1\\;of\\;Interaction\\;effect}}{\\frac{SS_{Within}}{df_2\\;of\\;Within\\;Variance}}\\]\n우리가 계산해야 할 세 개의 F-value를 위에 표현해 보았습니다. 좀 정리가 되시나요?\n그렇다면 이원배치 분산분석을 위한 통계적 가설은 몇 개가 필요할까요? 당연히 세 개가 필요합니다. 첫 번째 독립변수의 Main effect에 대한 통계적 가설은 아래와 같습니다.\n\\[ H_{01}: \\mu_{11} = \\mu_{12} = \\; ... \\; = \\mu_{1k} \\; (k는 그룹의 갯수)\\]\n\\[ H_{a1}: \\mu_{1i} \\neq \\mu_{1j} \\; for \\; some \\; i, j\\]\n동일한 방법으로 두 번째 독립변수의 Main effect에 대한 통계적 가설은 아래와 같습니다.\n\\[ H_{02}: \\mu_{21} = \\mu_{22} = \\; ... \\; = \\mu_{2k} \\; (k는 그룹의 갯수)\\]\n\\[ H_{a2}: \\mu_{2i} \\neq \\mu_{2j} \\; for \\; some \\; i, j\\]\n마지막으로 Interaction effect에 대한 통계적 가설은 다음과 같습니다.\n\\[ H_{03}: \\text{The interaction effect does not exist}\\]\n\\[ H_{a3}: \\text{The interaction effect exists}\\]\n여기서 주의할 점이 있습니다. 앞서 우리는 일원배치 분산분석에서 F-value가 유의하다는 것은 적어도 한 그룹의 평균값이 다르다는 의미이고, 이는 자세한 그룹별 차이를 알 수 없으므로 사후검정을 해야 한다고 이야기 했습니다. 이와 더불어 그래프를 그리는 것이 좋다는 이야기도 했습니다. 이원배치 분산분석에서도 이러한 원칙은 동일합니다. 다만 이 원칙은 두 개의 Main effect에 대한 F-value가 유의할 경우에만 동일합니다. Interaction effect를 확인하기 위한 F-value가 유의할 경우 이는 Interaction effect가 있다는 의미인데 문제는 사후검정을 할 경우 상당히 복잡한 문제가 발생합니다. 물론 사후검정을 할 필요가 있기는 하지만 경우에 따라서는 무의한 상황이 벌어지기도 합니다. 예를 들어 두 독립변수가 각각 3 개의 그룹을 가지고 있을 경우 두 변수의 조합에 의한 세부 그룹은 \\(3 \\times 3 = 9\\)가 됩니다. 즉 9개의 세부 그룹이 존재하게 되고 이 9개의 그룹을 1대1로 비교하려면 \\(9 \\times 8 \\div 2 = 36\\)이 되어 총 36개의 조합을 비교하는 상황이 벌어집니다. 사실 이렇게 많은 조합의 비교결과를 리포트 하는 것은 정신없기만 하고 중요한 내용을 오히려 빠뜨릴 수 있습니다. 그래서 보통 Interaction effect가 유의할 경우 사후검정은 연구자가 따로 해보기는 하지만 리포트하지는 않고 그래프를 반드시 리포트 하면서 해석을 할 때 사후검정 결과를 참고하는 것입니다. 엄청나게 긴 표에 들어 있는 많은 양의 정보보다 그림 한 장이 더 명쾌하기 때문입니다.\n이제 이원배치 분산분석의 F-value를 계산해 봅시다. 조금만 더 힘내기 바랍니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter1.html#이원배치-분산분석의-f-vlaue를-계산해-보자",
    "href": "chapter1.html#이원배치-분산분석의-f-vlaue를-계산해-보자",
    "title": "1  이원배치 분산분석 (Two-way ANOVA)",
    "section": "1.3 이원배치 분산분석의 F-vlaue를 계산해 보자",
    "text": "1.3 이원배치 분산분석의 F-vlaue를 계산해 보자\n\n1.3.1 이원배치 분산분석 예제\n이제 손으로 계산 가능한 아주 작은 크기의 예제를 한 가지 이용해서 F-value를 계산해 보겠습니다. 현실에서는 있을 수 없는 경우라는 점을 먼저 말씀드립니다. 왜냐하면 샘플 사이즈가 너무 작기 때문이지요. 여기서는 우리가 이원배치 분산분석의 F-value를 손으로 계산해서 구한다는 것을 목적으로 하기 때문에 가능한 것입니다.\n예제는 다음과 같습니다. 우리는 이제 두 가지 종류의 세탁세제의 세척력을 비교하고자 합니다. 다만 세제의 세척력이 물의 온도에 영향을 받는다고 알려져 있어서 세가지 종류의 물의 온도를 이용해 실험할 예정입니다. 두 세제의 이름은 Super와 Best이고, 물의 온도는 Cold, Warm, Hot 이렇게 나누기로 했습니다. 아래의 Table 1.3 를 보면 총 6개의 케이스(셀)가 있고 각 케이스별로 4회의 실험을 했습니다. 일단 숫자가 큰 것이 세척력이 좋은 것이라고 봅시다.\n\n\nTable 1.3: 이원배치 분산분석 예제\n\n\n\nCold\nWarm\nHot\n\n\n\n\nSuper\n4 / 5 / 6 / 5\n7 / 9 / 8 / 12\n10 / 12 / 11 / 9\n\n\nBest\n6 / 6 / 4 / 4\n13 / 15 / 12 / 12\n12 / 13 / 10 / 13\n\n\n\n\n\n\n1.3.2 이원배치 분산분석의 코딩방법\n여기서 잠시 이원배치 분산분석의 코딩에 대해 이야기 하겠습니다. 이미 경험이 있거나 통계를 잘 아시는 분들에게는 불필요 할 수 있으나 초보자에게는 항상 어려운 부분입니다. 앞서 계속해서 반복하는 내용이 있다면 바로 엑셀 시트에서 열(column) 한 개가 변수 한 개이다는 것입니다. 이원배치 분산분석에서 종속변수 한 개와 독립변수 두 개를 가지고 분석을 하기 때문에 당연히 우리는 총 3 개의 열(column)에 코딩을 하면 됩니다. 종속변수에 해당하는 한 개의 열(column)애는 연속변수의 형태를 가진 종속변수를 넣으면 되고, 두 개의 독립변수는 각각 두 개의 열(column)에 코딩합니다. 주의할 점은 첫 번째 독립변수인 세제는 두 가지의 그룹이 있다는 것이므로 한 개의 열(column)에 두 가지의 세제가 코딩되면 됩니다. 마찬가지로 두 번째 독립변수인 물의 온도는 세 가지의 그룹을 가지고 있으므로 한 개의 열(column)에 Cold, Warm, Hot 세 가지의 그룹이 코딩되면 됩니다. 절대 세 가지 그룹을 세 개의 열(column)에 코딩하면 안 됩니다. 마지막으로 Interaction에 대해 궁금해 하실 텐데 분산분석에서는 Interaction을 별도로 코딩하지 않습니다. 통계 프로그램이 알아서 Interaction term을 만들어서 계산해줍니다. 아래의 그림은 코딩된 결과입니다.\n\n\n\nFigure 1.11: 이원배치 분산분석 코딩결과\n\n\n\n\n1.3.3 F-value를 계산해 보자\n\n\nTable 1.4: F-value 계산을 위한 데이터 정리\n\n\n\n\n(a) 이원배치 분산분석 데이터\n\n\n\nCold\nWarm\nHot\n\n\n\n\nSuper\n4 / 5 / 6 / 5\n7 / 9 / 8 / 12\n10 / 12 / 11 / 9\n\n\nBest\n6 / 6 / 4 / 4\n13 / 15 / 12 / 12\n12 / 13 / 10 / 13\n\n\n\n\n\n\n\n\n(b) 평균값 테이블\n\n\n\nCold\nWarm\nHot\nMean\n\n\n\n\nSuper\n5.0\n9.0\n10.5\n8.2\n\n\nBest\n5.0\n13.0\n12.0\n10.0\n\n\nMean\n5.0\n11.0\n11.3\n9.1\n\n\n\n\n\n\n계산을 쉽게 하기 위해 데이터 테이블과 별도로 평균값 테이블을 Table 1.4 (b) 에 만들어 보았습니다. 가장 우측의 평균값은 Super 전체와 Best 전체의 평균값이고 가장 아래의 평균값은 Cold, Warm, Hot 전체의 평균값입니다. 마지막으로 가장 우측 아래의 9.1은 데이터 전체의 평균값입니다.\n우리가 계산할 총 4 개의 분산 중 첫 번째로 계산할 것은 바로 비교대상이면서 기준이 되는 Within Variance입니다. 앞의 일원배치 분산분석과 마찬가지로 Within Variance란 그룹 내의 분산입니다. 여기서는 총 6개의 그룹이 있다고 볼 수 있습니다. 먼저 분산의 윗부분인 분자부분을 계산하는 방식은 각 값에서 그 그룹의 평균값을 빼고 제곱하여 모두 더하는 방식입니다. 바로 \\(SS_{Within}\\)입니다.\n\\[ SS_{Within} = (4-5)^2 + (5-5)^2 + (6-5)^2 + (5-5)^2\\] \\[+ (7-9)^2 + (9-9)^2  + (8-9)^2 + (12-9)^2\\] \\[ \\; ...\\;  \\] \\[+ (12-12)^2 + (13-12)^ + (10-12)^2 + (13-12)^2 = 37.0 \\]\n이렇게 됩니다. 가능하면 직접 엑셀에 데이터를 넣고 계산해 보실 것을 권해드립니다. 직접 해보는 것만큼 좋은 공부가 없습니다. 이제 다름으로 분산의 아래 부분인 df를 구해 봅시다. \\(df_{Within}\\)의 공식이 좀 복잡해 보이지만 아래에 있습니다. 일단 \\(r\\)은 각 셀에서 반복된 실험 횟수입니다. 여기서는 4회이므로 \\(r = 4\\)입니다. \\(k_1\\)과 \\(k_2\\)는 두 독립변수의 그룹의 개수입니다. 그러므로 각각 2와 3이 되어 \\(df_{Within} = 18\\)입니다.\n\\[ df_{Within} = (r-1) \\times k_1 \\times k_2 = 3 \\times 2 \\times 3 = 18 \\]\n그러므로 Within Variance는 2.06이 됩니다.\n\\[ \\text{Within Variance} = \\frac{SS_{Within}}{df_{Within}} = \\frac{37.0}{18.0} = 2.06 \\]\n그럼 이제 첫 번째 독립변수의 Main effect에 대한 Between Variance를 구해 봅시다. 첫 번째 독립변수는 두 가징 종류의 세탁세제입니다. 이 Between Variance는 두 세탁세제 그룹의 평균값이 전체평균으로부터 얼마나 멀어져 있는 지를 구하는 것입니다. 그러므로 \\(SS_{Main \\; effect1}\\)의 계산은 아래와 같습니다.\n\\[ SS_{Main \\; effect1} = r \\times k_2 \\times \\{(8.2-9.1)^2 + (10.0-9.1)^2\\}\\] \\[= 12 \\times \\{(8.2-9.1)^2 + (10.0-9.1)^2\\} = 20.17 \\]\nSuper의 평균값이 8.2이고 Best의 평균값이 10.0이므로 이 두 값을 전체평균인 9.1로 뺀 뒤에 제곱합니다. 앞의 일원배치 분산분석을 차분하게 직접 계산해 보신분이라면 아시겠지만 만약 아니라면 왜 12를 곱하는지 궁금하실 것입니다. 이는 각 그룹을 살펴보면 Super가 총 12회 실험이 되어 12개의 데이터 값이 있고, Best 역시 총 12회 실험이 되어 12개의 데이터 값이 있기 때문입니다. 한 번만 하면 되지 않겠냐고 생각하실 수 있겠으나 이건 굉장한 오해입니다. 저 평균값 8.2와 10.0은 각각 12개의 데이터의 평균값에서 얻어진 것이므로 위의 제곱합 계산을 12회 한 것이 됩니다. 그러므로 12를 곱해야 합니다.\n이제 df를 알아보겠습니다. 여기서 df는 일원배치 분산분석과 동일합니다. 즉, 그룹의 개수에서 1을 빼는 것이지요. 따라서 이 경우에는 df는 1이 됩니다.\n\\[ df_{Main \\; effect1} = k_1 - 1 = 2 - 1 = 1 \\]\n이제 첫 번째 독립변수의 Main effect에 대한 Between Variance를 구해 보겠습니다.\n\\[ \\text{Between Variance} = MS_{Main \\; effect1} = \\frac{SS_{Main\\;effect1}}{df_{Main\\;effect1}} = \\frac{20.17}{1} = 20.17 \\]\n이제는 Between Variance라는 표현보다 \\(MS_{Main\\;effect1}\\) 이런 식의 표현을 주로 사용해보겠습니다. 왜냐하면 세 개의 Between Variance가 있다보니 말이 좀 길어지네요. 그렇다면 다음으로 \\(MS_{Main\\;effect2}\\)를 구해 보겠습니다.\n\\[ SS_{Main\\;effect2} = r \\times k_1 \\times \\{(5.0-9.1)^2 + (11.0-9.1)^2 + (11.3-9.1)^2\\}\\] \\[= 8 \\times \\{(5.0-9.1)^2 + (11.0-9.1)^2 + (11.3-9.1)^2\\} = 200.33 \\]\n이미 앞에서 한 번 해보았으니 이해가 되시겠지만 여기서 8을 곱하는 이유는 각 그룹당 8번씩의 실험을 해서 총 8개의 데이터가 있기 때문입니다. df 역시 그룹의 개수에서 1을 차감하면 되므로 2가 됩니다.\n\\[ df_{Main\\;effect2} = k_2 - 1 = 3 - 1 =2 \\]\n이 둘을 나누어 \\(MS_{Main\\;effect2}\\)를 구해보면 아래와 같습니다.\n\\[ MS_{Main\\;effect2} = \\frac{SS_{Main\\;effect2}}{df_{Main\\;effect2}} = \\frac{200.33}{2} = 100.17 \\]\n\n\n1.3.4 Interaction effect의 Between Variance를 구해보자\n이제 남은 것은 Interaction effect의 Between Variance입니다. 이게 좀 독특합니다. 그래서 이걸 이해하기 어려워 하는 분들이 좀 있지요. 하지만 가만 생각해보면 그다지 어렵지 않습니다. 일단 위의 데이터의 평균값 테이블 Table 1.4 (b) 을 잘 보고 아래의 계산식을 확인하시기 바랍니다.\n\\[ SS_{Interaction} = r \\times \\{(5.0-8.2-5.0+9.1)^2 + (9.0-8.2-11.0+9.1)^2 \\] \\[+ (10.5-8.2-11.3+9.1)^2 + (5.0-10.0-5.0+9.1)^2 \\] \\[+ (13.0-10.0-11.0+9.1)^2 + (12.0-10.0-11.3+9.1)^2 \\} = 16.33 \\]\n총 6번의 계산이 이루어지는데요. 모두 시작은 각 6개의 셀의 평균값인 5.0, 9.0, 10.5, 5.0, 13.0, 12.0입니다. 원칙은 간단합니다. 각 셀이 걸쳐져 있는 두 그룹의 평균값을 빼고 마지막에 전체평균값인 9.1을 더하는 방식입니다. 예를 들어 첫 번째 계산값은 Super이면서 Cold인 셀인데 이 셀의 평균값은 5.0입니다. 이 5.0에서 Super의 평균값인 8.2와 Cold의 평균값인 5.0을 빼고 마지막에 전체평균인 9.1을 더하는 방식입니다. 이 방식을 모든 6 개의 셀에 다 하는 것입니다. 물론 제곱해서 더해야 하지요. 앞의 r은 역시 4회의 반복실험으로 얻어진 4개의 데이터를 의미합니다. 그렇다면 왜 이런 식으로 구할까요? 좀 더 쉬운 이해를 위해 다음의 예제를 보시면 좀 이해가 되실 것입니다.\n\n\n\n\n\n\n\n(a) Interaction 없음\n\n\n\n\n\n\n\n(b) Interaction 있음\n\n\n\n\nFigure 1.12: Interaction 계산 예제\n\n\n위의 Figure 1.12 의 첫 번째 그림(Figure 1.12 (a))은 Interaction이 없는 경우이고 두 번째 그림(Figure 1.12 (b))은 Interaction이 있는 경우입니다. 이 두 개의 경우를 가지고 \\(SS_{Interaction}\\)을 계산해 보겠습니다. 아래의 표는 두 경우의 평균값을 정리한 것입니다.\n\n\nTable 1.5: Interaction의 계산 예제\n\n\n\n\n(a) Interaction 없는 경우\n\n\n\nX1의 Level 1\nX1의 Level 2\nMean\n\n\n\n\nX2의 Level 1\n2\n4\n3\n\n\nX2의 Level 2\n4\n6\n5\n\n\nMean\n3\n5\n4\n\n\n\n\n\n\n\n\n(b) Interaction 있는 경우\n\n\n\nX1의 Level 1\nX1의 Level 2\nMean\n\n\n\n\nX2의 Level 1\n2\n4\n3\n\n\nX2의 Level 2\n4\n2\n3\n\n\nMean\n3\n3\n3\n\n\n\n\n\n\n이제 그럼 첫 번째 케이스인 Interaction이 없는 경우에 대해서 \\(SS_{Interaction}\\)을 계산해 보겠습니다.\n\\[ SS_{Interaction} = (2-3-3+4)^2 + (4-3-5+4)^2 + (4-5-3+4)^2 + (6-5-5+4)^2 = 0 \\]\n그렇다면 두 번째인 Interaction이 있는 경우는 어떻게 될까요?\n\\[ SS_{Interaction} = (2-3-3+3)^2 + (4-3-3+3)^2 + (4-3-3+3)^2 + (2-3-3+3)^2 = 4 \\]\n어떤가요? Interaction이 없는 경우에는 계산이 0으로 딱 떨어집니다. 하지만 Interaction이 있는 경우에는 그렇지 않습니다. 이게 바로 Interaction의 계산법입니다. 이제 마지막으로 df를 알아보겠습니다. Interaction의 df 계산은 좀 복잡합니다.\n\\[ df_{Interaction} = (k_1 - 1) \\times (k_2 - 1) = 2 \\times 1 = 2 \\]\n\\[ MS_{Interaction} = \\frac{SS_{Interaction}}{df_{Interaction}} = \\frac{16.33}{2} = 8.17 \\]\n이렇게 됩니다. 이제 그럼 정리를 해 보겠습니다.\n\n\nTable 1.6: 이원배치 분산분석 결과표\n\n\n\n\n\n\n\n\n\n\n\nSS\ndf\nMS\nF-value\np-value\n\n\n\n\nDetergent\n20.167\n1\n20.167\n9.81\n0.0057584\n\n\nTemperature\n200.333\n2\n100.167\n48.73\n0.0000001\n\n\nInteraction\n16.333\n2\n8.167\n3.97\n0.0372243\n\n\nWithin\n37.000\n18\n2.056\n\n\n\n\nTotal\n273.833\n23\n\n\n\n\n\n\n\n왜 Table 1.6 와 같은 표가 나왔는지 이야기 하자면, 먼저 SS, df, MS는 모두 위에서 계산된 값입니다. 그러니 더 설명은 필요없겠지요. 이제 세 개의 F-value가 어떻게 계산되는지 아래의 내용을 보시기 바랍니다.\n\\[ F-value_{Detergent(1,18)} = 20.167 \\div 2.056 = 9.81 \\] \\[ F-value_{Temperature(2,18)} = 100.167 \\div 2.056 = 48.73 \\] \\[ F-value_{Interaction(2,18)} = 8.167 \\div 2.056 = 3.97 \\]\n이렇게 계산됩니다. 왜 이렇게 계산되는지는 앞의 일원배치 분산분석을 보셨다면 당연히 아실 것이라 생각하고 더 설명은 안하겠습니다. 위의 p-value를 엑셀에서 구하시려면 역시 fdist라는 엑셀의 함수를 사용하시면 됩니다. 매우 유용합니다.\n이제 이원배치 분산분석의 F-value 계산이 끝났습니다. 거의 마무리 되어 가네요. 조금만 더 힘을 내봅시다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter1.html#이원배치-분산분석의-사후검정",
    "href": "chapter1.html#이원배치-분산분석의-사후검정",
    "title": "1  이원배치 분산분석 (Two-way ANOVA)",
    "section": "1.4 이원배치 분산분석의 사후검정",
    "text": "1.4 이원배치 분산분석의 사후검정\n\n1.4.1 이원배치 분산분석 결과표\n우리는 앞서 손으로 계산 가능한 아주 작은 데이터를 이용해 F-value를 구하고 유의성 확인까지 했습니다. 이제 아래의 Figure 1.13 는 Jamovi로 동일한 데이터를 분석한 결과입니다. 우리가 위에서 계산한 것과 동일한 결과를 보여주고 있음을 알 수 있습니다. 두 개의 Main effect와 한 개의 Interaction effect 모두가 유의한 결과를 보였습니다.\n\n\n\nFigure 1.13: 이원배치 분산분석 결과표\n\n\n분산분석에서 F-value가 유의하다는 것은 Main effect의 경우 적어도 한 그룹의 평균값이 전체평균값에서 멀어져 있다는 것일 뿐 자세한 모양이나 내용에 대해서는 알 수 없고, Interaction effect 역시 단수하게 있다 업다만 알 수 있을 뿐 자세한 내용은 알 수 없습니다. 따라서 이 경우 사후 검정이 필요합니다.\n\n\n1.4.2 Main effect에 대한 사후검정\n먼저 첫 번째 Main effect에 대한 사후검정 결과를 보겠습니다. 이는 Detergent라는 독립변수에 대한 사후검정으로 이 독립변수는 단 두 개의 그룹을 가지고 있습니다.\n\n\n\nFigure 1.14: Detergent에 대한 사후검정 결과\n\n\nFigure 1.14 은 아주 단순한 결과를 보여줍니다. 여기서는 Tukey의 검정방법만 보이도록 했습니다. 다른 것들도 비슷한 결과이므로 크게 다르지 않습니다. 좌측에서 사후검정결과 유의하다는 결과를 보여줍니다. 왜냐하면 \\(P_{Tukey}\\) 값이 5%보다 작기 때문입니다. 문제는 이렇게 다르다고만 할 뿐 누가 더 세탁력이 좋은지는 잘 알 수 없습니다. 그래서 우측에 Descriptive statistics를 별도로 추가했습니다. 평균값이 best가 super보다 크다는 것을 알 수 있습니다. 이처럼 사후검정만으로는 사실 쉽게 전체적인 모양을 이해하기 쉽지 않습니다. 다시 평균값을 확인해야 하는 번거로움이 있지요. 그래서 그래프를 그리는 것이 중요합니다.\n이제 두 번째 Main effect에 대한 사후검정 결과를 보겠습니다. 이 변수는 Temperature라는 독립변수로 총 3 개의 그룹(Cold/Warm/Hot)을 가지고 있었습니다.\n\n\n\nFigure 1.15: Temperature에 대한 사후검정 결과\n\n\n그룹이 3 개이기 때문에 1대 1로 비교하기 위해서는 \\(3 \\times 2 \\div 2 = 3\\)으로 총 3 개의 비교가 나옵니다. 비교 결과 Cold vs. Warm 은 유의하게 다르다고 나왔고, Cold vs. Hot 역시 유의하게 다르다고 나왔습니다. 그러나 Warm vs. Hot은 유의하지 않았습니다. 보다 자세한 내용 파악을 하려면 우측의 그룹별 평균값을 보아야 합니다. Cold만 5.0으로 매우 세척효과가 작았고 Warm과 Hot은 11.0, 11.3으로 세척효과가 높으면서 둘은 서로 비슷하게 나타났습니다. 그러나 전체적인 모양이 표의 숫자만으로는 잘 이해가 되지 않습니다. 그래서 그래프가 필요한 것이지요.\n\n\n1.4.3 Interaction effect에 대한 사후검정\n이원배치 분산분석 결과표(Figure 1.13)에서 Interaction effect는 유의하다고 나타났습니다. 그렇다면 세부적으로 어떻게 다르다는 것일까요? 그 결과를 알기 위해 사후검정을 해보았습니다.\n\n\n\nFigure 1.16: Interaction effect의 사후검정 결과\n\n\nFigure 1.16 에서 보면 상당히 많은 내용이 있습니다. 왜냐하면 총 그룹의 개수가 6개 (\\(=2 \\times 3\\))이기 때문에 1대 1로 비교할 개수가 $ 6 = 15$이기 때문입니다. 총 15개의 비교가 있습니다. 첫 번째 줄만 해석을 해보자면 Super & Cold vs. Super & Warm의 비교는 유의한 차이를 보이다고 되어 있습니다. 이런 방식으로 15개의 결과를 글로 써서 리포팅 하는 것은 사실 상당히 시간소모는 많은 반면 읽는 사람 입장에서는 이해가 쉽지 않습니다. 그래서 Interaction effect가 유의하고 특히나 그룹의 개수가 이 정도가 되면 위와 같은 사후검정 테이블보다는 그래프가 훨씬 더 이해하기 쉽습니다. 그래프로 결과를 해석하면서 중간 중간 필요한 부분에 대한 해석을 할 때 위의 사후검정 결과를 인용하면서 해석하는 것이 보다 현명합니다.\n그럼 결과 그래프를 보겠습니다.\n\n\n\nFigure 1.17: 이원배치 분산분석 결과 그래프\n\n\nFigure 1.17 은 상당히 직관적이면서도 많은 정보를 줍니다. Jamovi에서 출력한 그래프인데 우선 동그란 점 6 개가 6개의 그룹의 평균값이고 위 아래로 있는 것이 95% confidence interval입니다. 쉽게 말하자면 평균값을 중심으로 95%의 데이터가 저 범위 안에 있다는 의미이기도 합니다. 일반적으로 95% confidence interval이 겹치면 두 평균값은 통계적으로 유의미한 차이를 보이지 않습니다. 즉 유의하지 않다는 의미가 됩니다. 그렇다면 이 그래프를 보면서 세부적인 해석을 해보도록 하겠습니다.\n우선 파란색의 가장 아래의 두 점은 Cold 그룹입니다. 한 눈에 보기에도 Cold에서는 Super와 Best가 차이가 없어 보입니다. 정말 그런지는 Figure 1.16 의 사후검정 결과를 확인해보며 알 수 있습니다. Figure 1.16 에서 Super & Cold vs. Best & Cold 는 \\(p_{Tukey}\\)값이 1.000 입니다. 즉 전혀 유의하지 않다는 의미입니다. 따라서 물이 차가운 경우에는 두 세탁세제의 세척력은 전혀 차이가 나지 않습니다. 재미있는 것은 Hot의 경우에도 Super와 Best의 95% confidence interval이 겹쳐 보입니다. 정말 그런지 Figure 1.16 에서 Super & Hot vs. Best & Hot을 보면 \\(p_{Tukey}\\)값이 0.681입니다. 그러므로 물의 온도가 뜨거워도 두 세탁세제의 세척력은 유의미한 차이가 없는 것이지요. 그러나 Warm에서는 두 세탁세제의 95% confidence interval이 겹치지 않아 보입니다. Figure 1.16 에서 보면 Super & Warm vs. Best & Warm의 \\(p_{Tukey}\\)값이 0.010인 것을 확인할 수 있습니다. 그러므로 두 세탁세제의 세척력은 물의 온도가 따뜻한 정도일 때 차이가 나고 이 경우 Best의 세척력이 더 통계적으로 우수하다는 것을 알 수 있습니다.\n다른 측면을 보면, Super의 경우 Hot과 Warm은 분명히 95% confidence interval이 겹쳐 보이고 Cold만 확실히 세척력이 낮아 보입니다. 이러한 양상은 Best도 동일합니다. 예를 들어 Super & Hot vs. Super & Warm은 \\(p_{Tukey}\\)값이 0.681, Best & Hot vs. Best & Warm은 \\(p_{Tukey}\\)값이 0.916이라는 것을 Figure 1.16 에서 확인할 수 있습니다.\n이와 같이 그래프를 먼저 제시하고 명확한 근거를 사후검정 테이블에서 찾아서 세부적인 해석을 하는 것이 보다 이해하기 쉽습니다. 분산분석은 그래서 항상 그래프를 잘 그려야 합니다. 이제 이해가 되시나요?\n이제 사실상 이원배치 분산분석이 다 끝났습니다. 다음은 부가적인 내용과 함께 실습이 남아 있습니다. 다들 수고하셨습니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter1.html#이원배치-분산분석에서-ss의-종류",
    "href": "chapter1.html#이원배치-분산분석에서-ss의-종류",
    "title": "1  이원배치 분산분석 (Two-way ANOVA)",
    "section": "1.5 이원배치 분산분석에서 SS의 종류",
    "text": "1.5 이원배치 분산분석에서 SS의 종류\n\n1.5.1 Sum of Squares의 종류\n혹시 Jamovi나 다른 통계 프로그램에서 ANOVA를 돌리다가 아래 화면과 같은 이상한 것을 발견한 분들이 있을지도 모릅니다.\n\n\n\nFigure 1.18: Type of SS\n\n\n이게 뭘까요?\n사실 모르는 게 약일 수도 있습니다만, 이런 걸 보고 그냥 지나치면 공부하는 사람의 자세가 아니라는 게 제 생각입니다. 일단 SS란 Sum of Squares의 약자로 우리가 F-value를 구할 때 먼저 계산했던 분자부분의 SS를 지칭합니다. 이 SS를 계산하는 방법이 세 가지 있다는 것이 결론입니다만, 자세한 계산방법은 여기서 논하지 않겠습니다. 뭐 정확하게 말하자면 저도 너무 어려워서 이해하기 어려울 정도라서요. 보통 Type I / II / III 로 불리는데, 제가 알기론 이러한 것들은 통계학에서 정한 것이 아니고 초기에 SAS라는 프로그램이 만들어질 때 프로그램 개발자들이 넣은 것이라는 이야기가 있습니다. 이게 사실 일원배치 분산분석 (One-way ANOVA)에서는 아무런 차이가 없구요. 독립변수가 2 개 이상인 분산분석 중 각 그룹의 데이터 개수가 동일하면 역시 차이가 없으나 데이터 개수가 다른 경우 달라진다고 합니다. 앞에서 F-value 계산할 때, r 값을 기억하시나요? 세탁세제의 예제에서 각 6개의 그룹 내에서 4 번씩 실험을 해서 \\(r = 4\\)였었던 그 값을 말합니다. 즉, r값이 동일하면 문제가 없는데 만약 r값이 그룹마다 다를 경우 계산 공식이 달라지겠지요. 그러면 이 경우 Type I / II / III의 종류에 따라서 결과값이 조금씩 달라진다는 것입니다. 각 SS 타입별로 특징을 정리해 보겠습니다.\n\n\n1.5.2 Type I SS\n제 1유형 제곱합이라고 부르며 순차 제곱합이라고도 합니다. 이 유형의 경우 변수를 한 개씩 순차적으로 추가하면서 제곱합을 계산하게 되어 있는데요. 다음의 순서로 계산이 됩니다.\n\nSS(A) for factor A\nSS(B | A) for factor B\nSS(AB | B, A) for interaction AB\n\n참고로 여기서 factor라고 하는 것은 독립변수를 말합니다. 가끔 이 용어를 뒤에 나올 요인분석의 요인과 헷갈리는 경우가 있는데요. 분산분석에서 독립변수를 오래 전에는 factor라고 불렀습니다. 오래된 영어책을 보실 일이 있다면 아마도 확인하실 수 있을 겁니다. 그래서 오래된 책에서는 분산분석을 아예 Factorial Analysis 라고 부르기도 했습니다.\n어쨌거나 위의 순서를 간략히 설명하자면 먼저 A라는 독립변수를 먼저 넣고 SS를 계산하고난 뒤에 A라는 변수를 조건부로 넣어 놓은 채로 B에 대한 SS를 구하고 마지막으로 A와 B를 조건부로 넣어 놓은 채로 Interaction의 SS를 계산한다는 의미입니다. 무엇이 문제냐면 이 경우 변수의 순서에 따라 SS가 변할 수 있다는 것입니다. 그러므로 특별한 목적에 맞춰서 사용하는 것이 좋고 중요한 변수를 먼저 감안한 뒤에 다른 추가 변수를 테스트하려할 경우에 하거나, 변동 불가능한 변수를 먼저 고려한 뒤에 변동 가능한 변수를 넣고 테스트하는 것이 좋습니다. 그러나 일반적으로 많이 쓰이지는 않습니다. 저도 논문에서 이 방법으로 분산분석을 한 것을 본적이 없습니다.\n\n\n1.5.3 Type II SS\n제 2유형 제곱합이라고 부르고, 이 유형의 경우 interaction은 제외하고 계산하는 것이 특징입니다. 계산 순서는 다음과 같습니다.\n\nSS(A | B) for factor A\nSS(B | A) for factor B\n\n그러므로, Interaction은 유의하지 않다고 전제하고 분산분석을 하는 것이지요.따라서, Interaction이 유의하지 않을 경우 사용하는 것이 좋다고는 합니다만 사실 이것 또한 저는 논문에서 본 적은 없습니다.\n\n\n1.5.4 Type III SS\n제 3유형 제곱합이라고 부르고 수정 제곱합이라고도 합니다. 다른 모든 독립변수들이 모두 이미 모형에 들어있다는 가정하에 마지막에 새로 추가되는 변수의 변동을 계산한 제곱합입니다. 계산 방식은 다음과 같습니다.\n\nSS(A | B, AB) for factor A\nSS(B | A, AB) for factor B\n\n변수의 순서에 따라 SS가 변화하지 않습니다. 가장 일반적으로 사용되는 SS는 Type III SS입니다. 그러므로 그냥 이 세번째 SS를 사용하면 됩니다. Jamovi에서 default로 셋팅된 SS가 바로 이 세 번째 SS입니다. 그러면 결과를 비교해 보겠습니다.\n\n\n1.5.5 SS Type별 비교\n\n\n\n\n\n\n\n(a) Type I SS\n\n\n\n\n\n\n\n(b) Type II SS with interaction\n\n\n\n\n\n\n\n\n\n(c) Type III SS\n\n\n\n\n\n\n\n(d) Type II SS without interaction\n\n\n\n\nFigure 1.19: Balanced Data 경우(r이 모두 동일한 경우)\n\n\nFigure 1.19 의 네 개의 결과를 비교해 보면 모든 결과가 동일하다는 것을 알 수 있습니다. 즉, 각 그룹별로 데이터의 개수가 완벽하게 똑같다면 어떤 것을 사용해도 결과는 차이가 없다는 것입니다.\n\n\n\n\n\n\n\n(a) Type I SS\n\n\n\n\n\n\n\n(b) Type III SS\n\n\n\n\n\n\n\n\n\n(c) Type I SS 다른 변수 순서\n\n\n\n\n\n\n\n(d) Type III SS 다른 변수 순서\n\n\n\n\nFigure 1.20: Unbalanced Data 경우(r이 다른 경우)\n\n\nFigure 1.20 를 보면 결과가 다 다르다는 것을 알 수 있습니다. 그렇다면 무엇을 써야 하느냐?\n특별한 이유가 없다면, Type III SS를 사용하는 것이 좋습니다. 단, interaction effect가 유의하지 않다면, Type II SS 가 더 좋을 수도 있다고 합니다만 솔직히 저는 개인적으로 논문에서 본적이 없어서 추천하기는 좀 그러네요. Type I SS를 사용할 경우에는, 변수의 순서를 조심해야 하는데 이 역시 추천하지 않습니다. 보통의 통계 프로그램은 제가 알기론 모두 Type III SS가 기본설정으로 되어 있을 것입니다. SAS의 경우 Type I SS와 Type III SS가 둘 다 결과표로 자동 제공 되는데, 이 경우 가급적 Type III SS로 결과 해석하는 것이 좋습니다. 저도 처음에 미국에서 석사시절 SAS로 분석할 때마다 조금씩 당황했던 기억이 있습니다. 궁금증이 해결되셨나요? 그렇다면 이제 실습으로 넘어가 봅시다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter1.html#이원배치-분산분석을-실습해-보자",
    "href": "chapter1.html#이원배치-분산분석을-실습해-보자",
    "title": "1  이원배치 분산분석 (Two-way ANOVA)",
    "section": "1.6 이원배치 분산분석을 실습해 보자",
    "text": "1.6 이원배치 분산분석을 실습해 보자\n이번에 사용할 데이터는 앞의 일원배치 분산분석에서 사용했던 데이터 입니다. 더불어 Figure 1.2 의 내용이 우리가 실습할 내용입니다. 항상 말씀드리지만 그냥 눈으로만 보시지 말고 직접 데이터를 다운 받아서 이것 저것 해보시길 권합니다.\n데이터 다운로드\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#contrasts에-대해-알아보자",
    "href": "chapter2.html#contrasts에-대해-알아보자",
    "title": "2  Contrasts 분석",
    "section": "2.1 Contrasts에 대해 알아보자",
    "text": "2.1 Contrasts에 대해 알아보자\n\n2.1.1 Constrasts란 무엇인가?\n우리는 앞서 ANOVA에서 F-value가 유의하면 사후검정을 한다고 했습니다. 그런데 만약 사후검정 말고 다른 방법이 있다면 어떨까요? 다음을 보기 바랍니다.\n만약, 수능 모의 수학시험을 고3학생, A대학의 수학과, 화학과, 영문학과, 그리고 역사학과 1학년 학생을 대상으로 실시했다면, 일반적인 ANOVA의 통계적 가설은 어떻게 될까요?\n\\[ H_0: \\mu_{고3} = \\mu_{수학과} = \\mu_{화학과} = \\mu_{영문학과} = \\mu_{역사학과} \\] \\[ H_a: \\text{5개 그룹의 수학 모의고사 점수 중 적어도 한 그룹의 점수는 다르다}\\]\n그런데, 만약 우리가 관심을 갖는 가설이 위와 같은 일반적인 ANOVA의 가설이 아닌 아래와 같은 가설이라면 어떻게 해야 할까요?\n\n고3 학생의 수학점수는 다른 네 그룹의 수학점수의 평균과 다르다.\n이공계 학과(수학과, 화학과) 신입생의 수학성적이 인문계 학과(영문학과, 역사학과) 신입생의 수학성적과 다르다.\n수학과 신입생의 수학성적이 화학과 신입생의 수학성적과 다르다.\n영문학과 신입생의 수학성적이 역사학과 신입생의 수학성적과 다르다.\n\n위의 새로운 가설 중 마지막 두 개는 t-test로 해결할 수도 있으나 앞의 두 개는 여태 우리가 배운 것으로는 해결이 불가능합니다. 또한 기존의 F-value의 결과나 사후검정으로는 위의 질문에 대한 답을 완벽하게 하기 어렵습니다. 이러한 류의 가설을 검증하기 위한 방법이 바로 Contrasts Analysis입니다. 사실 대부분의 통계책에서는 그다지 심도 있게 다루지 않기도 하고 많은 사회과학에서도 이 방법을 그다지 많이 쓰지는 않습니다. 그러나 사실 이 방법만이 가진 장점이 바로 위의 가설과 같은 전혀 다른 종류의 가설 검증이 가능하다는 것이기 때문에 저는 개인적으로 공부를 좀 해뒀던 편입니다. 문제는 저 조차도 마음으로는 이걸 좀 어디에 써 봐야겠다는 생각만 10여 년째 할뿐 아직까지는 논문에 적용하지 못하고 있기는 합니다. 일단 좀 더 자세하게 알아봅시다.\n\n\n2.1.2 Contrasts를 사용한 통계적 가설\n위의 네 가지 예를 사용해 contrasts를 이용한 통계적 가설을 만들어 봅시다. 우선 다섯 그룹은 아래의 표와 같이 나누기로 합니다.\n\n\nTable 2.1: 다섯 그룹의 예제\n\n\n\n\n\n\n\n\n\n고3\n수학과\n화학과\n영문학과\n역사학과\n\n\n\n\n\\(\\mu_1\\)\n\\(\\mu_2\\)\n\\(\\mu_3\\)\n\\(\\mu_4\\)\n\\(\\mu_5\\)\n\n\n\n\n\n고3 학생의 수학점수는 다른 네 그룹의 수학점수의 평균과 다르다.\n\n이 경우 고3 학생의 평균은 \\(\\mu_1\\)이 되고, 나머지 네 그룹의 평균은 \\(\\frac{\\mu_2+\\mu_3+\\mu_4+\\mu_5}{4}\\)가 되므로 통계적 가설은 다음과 같습니다.\n\\[ H_0: \\mu_1 = \\frac{\\mu_2+\\mu_3+\\mu_4+\\mu_5}{4} \\] \\[ H_a: \\mu_1 \\ne \\frac{\\mu_2+\\mu_3+\\mu_4+\\mu_5}{4} \\]\n이렇게 됩니다. 좀 이해가 되시나요? 이제 두번째 가설을 봅시다.\n\n이공계 학과(수학과, 화학과) 신입생의 수학성적이 인문계 학과(영문학과, 역사학과) 신입생의 수학성적과 다르다.\n\n이 가설을 contrasts를 이용한 통계적 가설로 바꾸면 아래와 같습니다.\n\\[ H_0: \\frac{\\mu_2+\\mu_3}{2} = \\frac{\\mu_4+\\mu_5}{2} \\] \\[ H_a: \\frac{\\mu_2+\\mu_3}{2} \\ne \\frac{\\mu_4+\\mu_5}{2} \\]\n이제 좀 더 이해가 되시죠? 나머지 둘은 사실 매우 쉽습니다.\n\n수학과 신입생의 수학성적이 화학과 신입생의 수학성적과 다르다.\n\n\\[ H_0: \\mu_2 = \\mu_3 \\] \\[ H_a: \\mu_2 \\ne \\mu_3 \\]\n\n영문학과 신입생의 수학성적이 역사학과 신입생의 수학성적과 다르다.\n\n\\[ H_0: \\mu_4 = \\mu_5 \\] \\[ H_a: \\mu_4 \\ne \\mu_5 \\]\n\n\n2.1.3 Contrasts란?\n일반적으로 contrasts란 특정한 비교를 위한 평균의 가중값으로 쉽게 말해 가중평균을 이용한 분석입니다. 모집단의 평균값(\\(\\mu\\))을 이용하여 contrasts 분석을 할 경우 아래와 같이 표현할 수 있습니다.\n\\[ \\Psi = \\sum_{i=1}^a c_i\\mu_i = c_1\\mu_1 + c_2\\mu_2 + c_3\\mu_3 + \\cdots + c_i\\mu_i \\]\n만약 표본/샘플의 평균값(\\(\\bar{X_i}\\))을 이용하는 경우는 이렇게 표현됩니다.\n\\[ \\hat{\\Psi} = \\sum_{i=1}^a c_i\\bar{X_i} = c_1\\bar{X_1} + c_2\\bar{X_2} + c_3\\bar{X_3} + \\cdots + c_i\\bar{X_i} \\]\n위의 식에서 \\(c_i\\)가 바로 contrasts입니다. 그렇다면 이걸로 어떻게 하라는 것일까요? 앞의 4개의 예제를 사용하여 선형조합의 contrasts를 만들어 보겠습니다. 단, \\(c_i\\) 는 그룹의 개수와 동일해야 하고, 모든 contrasts인 \\(c_i\\) 의 합은 “0” 이어야 합니다.\n\n\n2.1.4 연구가설 - 통계적 가설 - Contrasts\n그렇다면 이제 앞의 예제들을 하나씩 연구가설, 통계적 가설 그리고 Contrasts까지 한꺼번에 묶어서 정리해 보겠습니다.\n\n연구가설 1: 고3 학생의 수학점수는 다른 네 그룹의 수학점수의 평균과 다르다.\n통계적 가설 1: \\[ H_0: \\mu_1 = \\frac{\\mu_2+\\mu_3+\\mu_4+\\mu_5}{4} \\] \\[ H_a: \\mu_1 \\ne \\frac{\\mu_2+\\mu_3+\\mu_4+\\mu_5}{4} \\]\nContrasts: \\[ \\Psi_1 = \\mu_1 - \\frac{1}{4}\\mu_2 - \\frac{1}{4}\\mu_3 - \\frac{1}{4}\\mu_4 - \\frac{1}{4}\\mu_5 \\] \\[ c = (1, -\\frac{1}{4}, -\\frac{1}{4}, -\\frac{1}{4}, -\\frac{1}{4}) \\]\n\n좀 복잡해 보이긴 하지만 전체적으로 일관된 부분이 분명합니다. 두번째는 아래와 같습니다.\n\n연구가설 2: 이공계 학과(수학과, 화학과) 신입생의 수학성적이 인문계 학과(영문학과, 역사학과) 신입생의 수학성적과 다르다.\n통계적 가설 2: \\[ H_0: \\frac{\\mu_2+\\mu_3}{2} = \\frac{\\mu_4+\\mu_5}{2} \\] \\[ H_a: \\frac{\\mu_2+\\mu_3}{2} \\ne \\frac{\\mu_4+\\mu_5}{2} \\]\nContrasts: \\[ \\Psi_2 =  \\frac{1}{2}\\mu_2 + \\frac{1}{2}\\mu_3 - \\frac{1}{2}\\mu_4 - \\frac{1}{2}\\mu_5 \\] \\[ c = (0, \\frac{1}{2}, \\frac{1}{2}, -\\frac{1}{2}, -\\frac{1}{2}) \\]\n\n세 번째는 아래와 같습니다.\n\n연구가설 3: 수학과 신입생의 수학성적이 화학과 신입생의 수학성적과 다르다.\n통계적 가설 3: \\[ H_0: \\mu_2 = \\mu_3 \\] \\[ H_a: \\mu_2 \\ne \\mu_3 \\]\nContrasts: \\[ \\Psi_3 = \\mu_2 - \\mu_3 \\] \\[ c = (0, 1, -1, 0, 0) \\]\n\n마지막 네 번째는 다음과 같습니다.\n\n연구가설 4: 영문학과 신입생의 수학성적이 역사학과 신입생의 수학성적과 다르다.\n통계적 가설 4: \\[ H_0: \\mu_4 = \\mu_5 \\] \\[ H_a: \\mu_4 \\ne \\mu_5 \\]\nContrasts: \\[ \\Psi_4 = \\mu_4 - \\mu_5 \\] \\[ c = (0, 0, 0, 1, -1) \\]\n\n이제 우리는 Contrasts가 무엇인지 알게 되었습니다. 좀 독특한 가설을 검증하기 위해 사용할 수 있는 나름 꽤 유용한 도구인 셈이지요. 그렇다면 이제 Contrasts의 종류에 대해 알아보겠습니다. 이제부터는 다소 심화학습같은 느낌입니다. 잘 이해가 안되더라도 너무 신경쓰지 않으셔도 됩니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#contrasts의-종류",
    "href": "chapter2.html#contrasts의-종류",
    "title": "2  Contrasts 분석",
    "section": "2.2 Contrasts의 종류",
    "text": "2.2 Contrasts의 종류\n\n2.2.1 Type of contrasts\n사실 이 부분은 좀 어렵습니다. 저도 어려워서 처음에 많이 힘들어 했습니다. 그러니 여러분들은 너무 스트레스 받으실 필요는 없습니다. 일단 세 가지 종류의 contrasts가 있습니다.\n\nPairwise contrasts\nComplex contrasts\nOrthogonal contrasts\n\n하나씩 알아보겠습니다.\n\n\n2.2.2 Pairwise contrasts\n두 개 그룹의 평균을 비교할 때 사용하는 contrasts로서 두 개를 Pair라고 보기 때문에 이런 이름이 되었습니다. 그러므로 한 개의 contrast는 “1”, 다른 한 개의 contrast는 “-1”로 설정합니다. 만약 총 a개의 그룹이 있다면 \\(a \\times (a-1) \\div 2\\)개의 pair가 존재합니다. 위에서 보았던 마지막 두 개의 가설이 이 경우에 해당됩니다.\n\n연구가설: 수학과 신입생의 수학성적이 화학과 신입생의 수학성적과 다르다.\nContrasts: \\(\\Psi_3 = \\mu_2 - \\mu_3\\), \\(c = (0, 1, -1, 0, 0)\\)\n연구가설: 영문학과 신입생의 수학성적이 역사학과 신입생의 수학성적과 다르다.\nContrasts: \\(\\Psi_4 = \\mu_4 - \\mu_5\\), \\(c = (0, 0, 0, 1, -1)\\)\n\n\n\n2.2.3 Complex contrasts\n두 개 이상의 그룹의 평균을 비교할 때 사용하는 contrasts로서 목적이나 상황에 따라 무한개의 contrasts를 만들 수 있습니다. 위에서 보았던 처음 두 개의 가설이 이 경우에 해당한다고 볼 수 있습니다.\n\n연구가설: 고3 학생의 수학점수는 다른 네 그룹의 수학점수의 평균과 다르다.\nContrasts: \\(\\Psi_1 = \\mu_1 - \\frac{1}{4}\\mu_2 - \\frac{1}{4}\\mu_3 - \\frac{1}{4}\\mu_4 - \\frac{1}{4}\\mu_5\\), \\(c = (1, -\\frac{1}{4}, -\\frac{1}{4}, -\\frac{1}{4}, -\\frac{1}{4})\\)\n연구가설: 이공계 학과(수학과, 화학과) 신입생의 수학성적이 인문계 학과(영문학과, 역사학과) 신입생의 수학성적과 다르다.\nContrasts: \\(\\Psi_2 = \\frac{1}{2}\\mu_2 + \\frac{1}{2}\\mu_3 - \\frac{1}{2}\\mu_4 - \\frac{1}{2}\\mu_5\\), \\(c = (0, \\frac{1}{2}, \\frac{1}{2}, -\\frac{1}{2}, -\\frac{1}{2})\\)\n\n사실상 Complex contrasts는 contrasts의 총합이 0이 되기만 한다면 어떤 조합도 허용됩니다. 예를 들면 아래의 경우도 허용됩니다.\n\nContrasts: \\(\\Psi_k = {\\small 0.01\\mu_1 - 0.08\\mu_2 - 0.98\\mu_3 + 0.58\\mu_4 + 0.47\\mu_5},\\\\ \\;\\;\\;\\;\\;\\;{\\small c = (0.01, -0.08, -0.98, 0.58, 0.47)}\\)\n\n그러나 이 경우 문제는 분석결과가 유의하게 나온다고 해도 해석이 안됩니다. 누가 봐도 그냥 아무 숫자나 넣어서 합이 0이되게 만들기만 한 것이기 때문입니다. 그르므로, 아무렇게나 하면 안됩니다. 분명한 이론이나 논리적 가설이 있고 이것을 바탕으로 contrasts가 만들어져야 합니다.\n\n\n2.2.4 Orthogonal contrasts\nNon-redundant contrasts 라고 부르기도 합니다. 이는 더이상 겹치거나 낭비되는 것이 없는 contrasts라는 의미입니다. 뒤에서 좀 더 자세하게 알아보겠습니다. 통계에서 “orthogonal”이란 직각, 겹치지 않는, 혹은 상관관계가 없다는 의미입니다. 의외로 자주 등장하는 개념이니 잘 기억해 두시길 바랍니다. 제가 미국에서 통계학과 수업을 들을 때, 교수님이 Orthogonal과 independent는 다르다는 이야기를 참 많이 강조했던 기억이 나네요. Orthogonal하다는 것은 상관관계가 없다는 것이지 상호 독립이란 의미는 아닙니다. 특히 Orthogonal은 서로 직각의 관계에 있다고 표현을 합니다. 뒤에서 계속 이런 것이 나올 것입니다.\n다음은 orthogonal 하지 않은 예 입니다.\n\n수학과 신입생의 수학점수가 고3 학생의 수학점수와 다르다.\nContrasts: \\(\\Psi_1 = \\mu_2 - \\mu_1\\), \\(c = (-1, 1, 0, 0, 0)\\)\n화학과 신입생의 수학점수가 고3 학생의 수학점수와 다르다.\nContrasts: \\(\\Psi_2 = \\mu_3 - \\mu_1\\), \\(c = (-1, 0, 1, 0, 0)\\)\n수학과 신입생의 수학점수가 화학과 신입생의 수학점수와 다르다.\nContrasts: \\(\\Psi_3 = \\mu_2 - \\mu_3\\), \\(c = (0, 1, -1, 0, 0)\\)\n\n이제 우리는 여기에 약간의 좀 복잡한 계산을 할 것입니다. 사실 덧셈, 뺄셈 수준이지만 최종 목적을 모르고서는 도대체 뭐하는 것인지 잘 이해가 되지 않을 수도 있습니다. 차근차근 보시기 바랍니다. 일단 시작은 위의 \\(\\Psi_1\\)입니다. 위에서 \\(\\Psi_1 = \\mu_2 - \\mu_1\\)였습니다. 이제 이 식에 \\(\\mu_3\\)를 한 번 더하고 한 번 빼 보겠습니다. 한 번 더하고 한 번 뺀다는 것은 사실 원래의 식 자체에 아무런 변화를 주지 않는 것입니다. 이렇게 표현할 수 있습니다. \\(\\Psi_1 = \\mu_2 - \\mu_1 -\\mu_3 + \\mu_3\\). 이제 이 식을 좀 다른 순서로 묶어 보겠습니다. \\(\\Psi_1 = (\\mu_2 -\\mu_3) + (\\mu_3 - \\mu_1)\\). 이제 이 두 묶음은 위의 두 번째와 세 번째의 가설과 일치히므로 이렇게 결론 내릴 수 있습니다. \\(\\Psi_1 = (\\mu_2 -\\mu_3) + (\\mu_3 - \\mu_1) = \\Psi_3 + \\Psi_2\\). 이렇게 된다는 것은 어떤 의미가 되냐면 만약 우리가 \\(\\Psi_3\\)와 \\(\\Psi_2\\)를 알고 있다면 이 둘을 더해서 자연스럽게 \\(\\Psi_1\\)을 알 수 있다는 것입니다. 따라서 이렇게 되면 \\(\\Psi_1\\)은 redundant하다고 보고 이 세 contrasts의 조합은 orthogonal하지 않다고 결론 내리게 됩니다.\n\n\n2.2.5 Orthogonality란 무엇인가?\n사실 설명이 다소 어렵기도 하고 오해의 소지도 있긴 합니다만 조심스럽게 설명해 보겠습니다.\n첫 번째로 개별 contrast 상호 간에 독립인 경우를 의미합니다. 여기서 독립이란 한 두 개의 contrast 값을 알고 있을 때, 다른 contrast 값을 알 수 없어야 한다는 것을 의미합니다. 위에서 본 것처럼 예를 들어 두 개의 contrast 값의 조합으로 다른 contrast 값을 알 수 있다면 이 경우는 orthogonal 하지 않은 것이지요. 그리고 한 세트의 contrast들이 orthogonal 하다면 contrast의 계수는 상관관계가 0이 됩니다. 이 것은 두 개의 contrast가 공간상에서 직각일 경우를 의미하는데요 이를 계산하는 방법은 다음과 같습니다.\n\n두 contrasts의 비교 개수가 동일 한 경우 (\\(a = b\\))\n\n\\(\\Psi_1 = (a_1, a_2, a_3, \\ldots, a_n)\\)\n\\(\\Psi_2 = (b_1, b_2, b_3, \\ldots, b_n)\\)\n\\(a_1b_1 + a_2b_2 + a_3b_3 + \\ldots + a_nb_n = 0\\)\n\n\n위의 마지막 계산식에서 최종적으로 0이 되면 두 contrasts는 orthogonal 합니다.\n\n두 contrasts의 비교 개수가 다른 경우 (\\(a &lt; b\\))\n\n\\(\\Psi_1 = (a_1, a_2, a_3, \\ldots, a_a)\\)\n\\(\\Psi_2 = (b_1, b_2, b_3, \\ldots, b_b)\\)\n\\(\\frac{a_1b_1}{n_1} + \\frac{a_2b_2}{n_2} + \\frac{a_3b_3}{n_3} + \\ldots + \\frac{a_ab_a}{n_a} = 0\\)\n\n\n이런 식이 됩니다. 일단 우리는 좀 쉬운 케이스 중심으로 예제를 진행해 보겠습니다.\n\n예제 1: \\(c_1 = (1, 0, -1)\\), \\(c_2 = (\\frac{1}{2}, -1, -\\frac{1}{2})\\)\n\n\\(\\sum a_nb_n = (1 \\times \\frac{1}{2}) + (0 \\times -1) + (-1 \\times \\frac{1}{2}) = \\frac{1}{2} + 0 - \\frac{1}{2} = 0\\)\n\\(c_1 \\bot c_2\\)\n\n예제 2: \\(c_3 = (0, 1, -1)\\), \\(c_2 = (-1, \\frac{1}{2}, \\frac{1}{2})\\)\n\n\\(\\sum a_nb_n = (0 \\times -1) + (1 \\times \\frac{1}{2}) + (-1 \\times \\frac{1}{2}) = 0 + \\frac{1}{2} - \\frac{1}{2} = 0\\)\n\\(c_3 \\bot c_4\\)\n\n예제 3: \\(c_5 = (1, -1, 0)\\), \\(c_6 = (1, 0, -1)\\)\n\n\\(\\sum a_nb_n = (1 \\times 1) + (-1 \\times 0) + (0 \\times -1) = 1 + 0 + 0 = 1\\)\n\\(c_3\\) 와 \\(c_4\\)는 상호간 orthogonal 하지 않다.\n\n예제 4: \\(c_1 = (1, -1, 0, 0)\\), \\(c_2 = (1, 1, -2, 0)\\), \\(c_3 = (1, 1, 1, -3)\\)\n\n\\(\\sum c_{1i}c_{2i} = (1 \\times 1) + (-1 \\times 1) + (0 \\times -2) + (0 \\times 0) = 1 - 1 + 0 + 0 = 0\\)\n\\(\\sum c_{1i}c_{3i} = (1 \\times 1) + (-1 \\times 1) + (0 \\times 1) + (0 \\times -3) = 1 - 1 + 0 + 0 = 0\\)\n\\(\\sum c_{2i}c_{3i} = (1 \\times 1) + (1 \\times 1) + (-2 \\times 1) + (0 \\times -3) = 1 + 1 - 2 + 0 = 0\\)\n그러므로 \\(c_1 \\bot c_2\\), \\(c_1 \\bot c_3\\), \\(c_2 \\bot c_3\\)\n따라서 모든 세트가 서로 orthogonal 하다.\n\n\n이론적으로는 n개의 그룹이 한 변수 안에 있을 경우 n-1개의 orthogonal contrasts가 있다고 합니다. 만약 이 개수를 넘으면 그 중에 redundancy가 있다는 의미가 되는 것이지요. 하지만 테스트 가능한 contrasts는 모두 orthogonal 해야할 필요는 없습니다. 그렇다면 왜 자꾸 orthogonal contrasts를 강조할까요? 이유는 간단합니다. orthogonal contrasts의 경우 이점이 있기 때문입니다.\n만약 우리가 orthogonal contrasts를 만들었다면, contrasts의 개수는 아마도 k-1개 (k는 그룹의 개수)가 될 것이고 이 경우 F-value의 계산에 사용되는 \\(SS_{Between}\\)이 k-1개의 \\(SS_{contrasts}\\)로 분할 가능하기 때문입니다. 즉, 이런 식으로 되는 것입니다.\n\n\\(SS_{Between} = SS_{contrast1} + SS_{contrast2} + SS_{contrast3} + \\ldots + SS_{contrastk-1}\\)\n앞서 우리는 \\(SS_{Between}\\)을 \\(df_1\\)으로 나눌 때, 자유도가 k-1이었음을 감안하면,\n이는 위의 \\(SS_{Between}\\)은 k-1개의 \\(SS_{contrasts}\\)의 합이 됩니다.\n여기서 1이 빠지는 이유는 그 빠진 1이 비교대상인 reference group이기 때문입니다.\n\n이제 기본적인 contrasts에 대한 공부는 끝났습니다. 이제 본격적으로 분석을 해보도록 합시다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#contrasts의-유의성을-테스트해-보자",
    "href": "chapter2.html#contrasts의-유의성을-테스트해-보자",
    "title": "2  Contrasts 분석",
    "section": "2.3 Contrasts의 유의성을 테스트해 보자",
    "text": "2.3 Contrasts의 유의성을 테스트해 보자\n\n2.3.1 Contrasts test 예제\n다음은 우리가 테스트 해볼 아주 작은 사이즈의 예제입니다. 다음의 표(Table 2.2)에는 데이터가 정리되어 있습니다.\n\n\nTable 2.2: 예제 데이터\n\n\nGroup\nConstant\nFrequent\nInfrequent\nNever\n\n\n\n\n보상방법\n(100% 보상)\n(66% 보상)\n(33% 보상)\n(0% 보상)\n\n\n1\n12\n9\n15\n17\n\n\n2\n13\n10\n16\n18\n\n\n3\n11\n9\n17\n12\n\n\n4\n12\n13\n16\n18\n\n\n5\n12\n14\n16\n20\n\n\nMean\n12\n11\n16\n17\n\n\n\n\n아동의 학습에 있어 보상의 역할을 알기 위해 아동 학습에 보상을 다르게 주고, 몇 번 만에 문제를 해결하는지 알기 위해 실험을 하였습니다. 총 4 개의 그룹으로 나누어 보상의 수준을 다르게 하였고, 각 그룹별로 5명의 아이들을 실험에 참가하게 하여 결과를 정리했습니다. Table 2.2 의 마지막 열(row)에는 각 그룹별 평균값이 나타나 있습니다.\n이제 우리는 다음의 세 개의 연구가설을 검증해 볼 것입니다.\n\nConstant(100%) 보상 그룹은 다른 보상 그룹들의 평균보다 학습시간이 더 빠르다.\nFrequent(66%) 보상 그룹은 Infrequent(33%) 보상 그룹이나 Never(0%) 보상그룹에 비해 학습시간이 더 빠르다.\nInfrequent(33%) 보상 그룹은 Never(0%) 보상 그룹에 비해 학습시간이 더 빠르다.\n\n결국 전반적으로는 보상을 더 자주 해주는 그룹의 아동들의 학습시간이 더 빠를 것이라는 예상을 하고 이를 위의 세 가지 가설로 만들어 검증하고자 하는 것입니다. 이제 이 검증방법의 프로세스를 정리해 보면 아래와 같습니다.\n\n연구가설을 contrasts로 바꾼다.\nContrasts가 orthogonal한지 알아본다.\n각 contrasts의 값을 계산한다.\n(omnibus) ANOVA를 통해 \\(MS_{Within}\\) 값을 구한다.\n각 contrasts의 표준오차를 구한다.\n각 contrasts의 t값 또는 F값을 구한다.\ndf를 참고하여 값이 유의한지 확인한다.\n\n앞에서 공부한 일원배치 혹은 이원배치 분산분석보다는 테스트 과정이 좀 복잡합니다. 하지만 하나씩 알아 봅시다.\n\n\n2.3.2 Contrasts Test\n\n연구가설을 contrasts로 바꾼다.\n\n\n가설 1: Constant(100%) 보상 그룹은 다른 보상 그룹들의 평균보다 학습시간이 더 빠르다.\n\nContrast: \\(c_1 = (1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3})\\)\n\n가설 2: Frequent(66%) 보상 그룹은 Infrequent(33%) 보상 그룹이나 Never(0%) 보상그룹에 비해 학습시간이 더 빠르다.\n\nContrast: \\(c_2 = (0, 1, -\\frac{1}{2}, -\\frac{1}{2})\\)\n\n가설 3: Infrequent(33%) 보상 그룹은 Never(0%) 보상 그룹에 비해 학습시간이 더 빠르다.\n\nContrast: \\(c_3 = (0, 0, 1, -1)\\)\n\n\n\nContrasts가 orthogonal한지 알아본다.\n\n\nContrasts: \\(c_1 = (1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3})\\), \\(c_2 = (0, 1, -\\frac{1}{2}, -\\frac{1}{2})\\), \\(c_3 = (0, 0, 1, -1)\\)\n\\(c_1\\) & \\(c_2\\): \\(\\sum c_{1i}c_{2i} = (1 \\times 0) + (-\\frac{1}{3} \\times 1) + (-\\frac{1}{3} \\times -\\frac{1}{2}) + (-\\frac{1}{3} \\times -\\frac{1}{2}) = 0\\): \\(c_1 \\bot c_2\\)\n\\(c_1\\) & \\(c_3\\): \\(\\sum c_{1i}c_{3i} = (1 \\times 0) + (-\\frac{1}{3} \\times 0) + (-\\frac{1}{3} \\times 1) + (-\\frac{1}{3} \\times -1) = 0\\): \\(c_1 \\bot c_3\\)\n\\(c_2\\) & \\(c_3\\): \\(\\sum c_{2i}c_{3i} = (0 \\times 0) + (1 \\times 0) + (-\\frac{1}{2} \\times 1) + (-\\frac{1}{2} \\times -1) = 0\\): \\(c_2 \\bot c_3\\)\n그러므로 모든 contrasts 세트는 orthogonal 하다.\n\n\n각 contrasts의 값을 계산한다.\n\n\nContrasts: \\(c_1 = (1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3})\\), \\(c_2 = (0, 1, -\\frac{1}{2}, -\\frac{1}{2})\\), \\(c_3 = (0, 0, 1, -1)\\)\n\\(\\hat{\\Psi_1} = \\bar{X_1} - \\frac{1}{3}\\bar{X_2} - \\frac{1}{3}\\bar{X_3} - \\frac{1}{3}\\bar{X_4} = 12 - \\frac{11}{3} - \\frac{16}{3} - \\frac{17}{3} = -2.667\\)\n\\(\\hat{\\Psi_2} = \\bar{X_2} - \\frac{1}{2}\\bar{X_3} - \\frac{1}{2}\\bar{X_4} = 11 - \\frac{16}{2} - \\frac{17}{2} = -5.5\\)\n\\(\\hat{\\Psi_3} = \\bar{X_3} - \\bar{X_4} = 16 - 17 = -1\\)\n\n\n(omnibus) ANOVA를 통해 \\(MS_{Within}\\) 값을 구한다.\n\n\n여기서 (omnibus) ANOVA란 단순히 일원배치 분산분석을 의미합니다.\n위의 Table 2.2 의 데이터를 Jamovi에 넣고 돌려보시기 바랍니다.\n다만, 위의 테이블 모양대로 넣으면 분석이 안됩니다. 위의 숫자는 모두 종속변수이며, 5 개씩 독립변수를 만들어 주어야 합니다.\nJamovi를 돌린 결과는 아래의 Figure 2.1 입니다.\n\\(MS_{Within}\\)값은 3.88입니다.\n\n\n\n\nFigure 2.1: (omnibus) ANOVA 결과\n\n\n\n각 contrasts의 표준오차를 구한다.\n\n\n\\(SE(\\hat{\\Psi_i}) = \\sqrt{MS_{Within} \\times \\sum_i^k \\frac{c_i^2}{n_i}}\\)\n\\(SE(\\hat{\\Psi_1}) = \\sqrt{3.88 \\times (\\frac{1^2}{5}+\\frac{(-\\frac{1}{3})^2}{5}+\\frac{(-\\frac{1}{3})^2}{5}+\\frac{(-\\frac{1}{3})^2}{5})} = \\sqrt{3.88 \\times 0.267} = 1.0165\\)\n\\(SE(\\hat{\\Psi_2}) = \\sqrt{3.88 \\times (0+\\frac{(1)^2}{5}+\\frac{(-\\frac{1}{2})^2}{5}+\\frac{(-\\frac{1}{2})^2}{5})} = \\sqrt{3.88 \\times 0.30} = 1.0782\\)\n\\(SE(\\hat{\\Psi_3}) = \\sqrt{3.88 \\times (0+0+\\frac{(1)^2}{5}+\\frac{(-1)^2}{5})} = \\sqrt{3.88 \\times 0.40} = 1.2450\\)\n\n\n각 contrasts의 t값 또는 F값을 구한다.\n\n\n\\(t(\\hat{\\Psi_i}) = \\frac{\\sum_{i=1}^k c_i\\bar{X_i}}{\\sqrt{MS_{Within} \\times \\sum_{i=1}^k \\frac{c_i^2}{n_i}}}\\)\n\\(t(\\hat{\\Psi_1}) = -2.667 \\div 1.0165 = -2.6237\\)\n\\(t(\\hat{\\Psi_2}) = -5.5 \\div 1.0782 = -5.1011\\)\n\\(t(\\hat{\\Psi_3}) = -1 \\div 1.2450 = -0.0832\\)\n여기서 \\(df = N - k = 20 - 4 = 16\\)이고 t-table에서 c.v.는 2.120 이므로\n\\(|t(\\hat{\\Psi_1})| &gt; 2.120 \\rightarrow \\text{p-value} &lt; 0.05\\)\n\\(|t(\\hat{\\Psi_2})| &gt; 2.120 \\rightarrow \\text{p-value} &lt; 0.05\\)\n\\(|t(\\hat{\\Psi_3})| &lt; 2.120 \\rightarrow \\text{p-value} &gt; 0.05\\)\n그러므로 첫 번째와 두 번째 contrast는 유의하지만 세 번째 contrast는 유의하지 않다.\n\n만약, 이 테스트를 F-value를 이용할 경우\n\n\\(SS(\\hat{\\Psi_i}) = \\frac{\\hat{\\Psi_i}^2}{\\sum_{i=1}^k \\frac{c_i^2}{n_i}}\\)\n\\(SS(\\hat{\\Psi_1}) = \\frac{(-2.667)^2}{\\frac{1^2}{5}+\\frac{(-\\frac{1}{3})^2}{5}+\\frac{(-\\frac{1}{3})^2}{5}+\\frac{(-\\frac{1}{3})^2}{5}} = 26.67\\)\n\\(SS(\\hat{\\Psi_2}) = \\frac{(-5.5)^2}{0+\\frac{1^2}{5}+\\frac{(-\\frac{1}{2})^2}{5}+\\frac{(-\\frac{1}{2})^2}{5}} = 100.83\\)\n\\(SS(\\hat{\\Psi_3}) = \\frac{(-1)^2}{0+0+\\frac{1^2}{5}+\\frac{(-1)^2}{5}} = 2.5\\)\n위의 Figure 2.1 을 정리한 표는 아래와 같다.\n\n\n\nTable 2.3: (omnibus) ANOVA 결과표\n\n\n\nSS\ndf\nMS\nF\n\n\n\n\nBetween\n130\n3\n43.33\n11.2\n\n\nWithin\n62\n16\n3.88\n\n\n\n\n\n\n이제 여기의 \\(SS_{Between}\\)을 contrast 세 개로 쪼개보겠습니다. 이게 가능한 이유는 우리가 계산한 \\(SS_{contrast}\\) 세 개의 합이 \\(SS_{Between}\\)이 되기 때문입니다.\n\n\n\nTable 2.4: Contrasts Test 결과표\n\n\n\nSS\ndf\nMS\nF\n\n\n\n\nBetween\n130\n3\n43.33\n11.2\n\n\n\\(\\hat{\\Psi_1}\\)\n26.67\n1\n26.67\n6.882\n\n\n\\(\\hat{\\Psi_2}\\)\n100.83\n1\n100.83\n26.021\n\n\n\\(\\hat{\\Psi_3}\\)\n2.5\n1\n2.5\n0.645\n\n\nWithin\n62\n16\n3.88\n\n\n\n\n\n\n위에서 보듯이 orthogonal contrasts가 되면 이렇게 df=1로 모든 contrasts를 쪼개어 사용할 수 있기 때문에 사실 orthogonality를 선호하는 것입니다.\n\n이제 가장 어려운 부분은 끝났습니다. 조금만 더 힘을 내서 마무리해 봅시다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#brand-contrasts에-대해-알아보자",
    "href": "chapter2.html#brand-contrasts에-대해-알아보자",
    "title": "2  Contrasts 분석",
    "section": "2.4 Brand contrasts에 대해 알아보자",
    "text": "2.4 Brand contrasts에 대해 알아보자\nBrand contrasts란 이미 웬만한 통계 프로그램에 자동으로 들어간 contrasts를 말합니다. 이정도로 유명하다면 한 번 살펴볼 필요는 있다고 볼 수 있죠. 현재, Jamovi는 완전하게 개발된 상태입니다. 제가 유투브를 올릴 당시만해도 아직 정식버전이 아니었습니다. 그러나 여전히 우리가 앞 시간에 봤던 contrasts는 테스트가 불가능합니다. 물론, 돈 주고 사야하는 다른 통계 프로그램들에서는 가능합니다. 솔직히 저도 아주 오래전에 SAS에서 해보고는 오랫동안 해보지는 않았네요. 하지만, 이 Brand contrasts는 Jamovi에서도 가능합니다. 그래서 이번에는 Jamovi를 기준으로 Brand contrasts를 하나씩 알아보겠습니다.\n\nDeviation contrasts\n\n\n한 그룹의 평균을 전체 평균과 비교하는 방법\nNon-orthogonal contrasts\n예를 들면, \\(\\mu_1 = \\frac{\\mu_1+\\mu_2+\\mu_3+\\mu_4}{4} \\rightarrow c = (-\\frac{3}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})\\)\n\\(c_1 = (-\\frac{3}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})\\)\n\\(c_2 = (\\frac{1}{4}, -\\frac{3}{4}, \\frac{1}{4}, \\frac{1}{4})\\)\n\\(c_3 = (\\frac{1}{4}, \\frac{1}{4}, -\\frac{3}{4}, \\frac{1}{4})\\)\n\\(c_1\\) & \\(c_2\\) = \\((-\\frac{3}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times -\\frac{3}{4})+(\\frac{1}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times \\frac{1}{4}) \\ne 0\\)\n\\(c_1\\) & \\(c_3\\) = \\((-\\frac{3}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times -\\frac{3}{4}) \\ne 0\\)\n\\(c_2\\) & \\(c_3\\) = \\((\\frac{1}{4} \\times \\frac{1}{4})+(-\\frac{3}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times \\frac{1}{4})+(\\frac{1}{4} \\times -\\frac{3}{4}) \\ne 0\\)\n\n\nSimple contrasts\n\n\n가장 마지막 그룹(레벨)을 비교기준(reference group)으로 하여 비교하는 방법\nNon-orthogonal contrasts\n\\(c_1 = (1, 0, 0, -1)\\)\n\\(c_2 = (0, 1, 0, -1)\\)\n\\(c_3 = (0, 0, 1, -1)\\)\n\\(c_1\\) & \\(c_2\\) = \\((1 \\times 0)+(0 \\times 1)+(0 \\times 0)+(-1 \\times -1) = 1\\)\n\\(c_1\\) & \\(c_3\\) = \\((1 \\times 0)+(0 \\times 0)+(0 \\times 1)+(-1 \\times -1) = 1\\)\n\\(c_2\\) & \\(c_3\\) = \\((0 \\times 0)+(1 \\times 0)+(0 \\times 1)+(-1 \\times -1) = 1\\)\n\n\nDifference contrasts\n\n\n한 그룹과 그 앞의 그룹들의 평균을 비교하는 방법\nOrthogonal contrasts with equal n\n\\(c_1 = (-1, 1, 0, 0)\\)\n\\(c_2 = (-\\frac{1}{2}, -\\frac{1}{2}, 1, 0)\\)\n\\(c_3 = (-\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3}, 1)\\)\n\\(c_1\\) & \\(c_2\\) = \\((-1 \\times -\\frac{1}{2})+(-1 \\times \\frac{1}{2})+(0×1)+(0×0) = 0\\)\n\\(c_1\\) & \\(c_3\\) = \\((-1 \\times -\\frac{1}{3})+(1 \\times -\\frac{1}{3})+(0 \\times -\\frac{1}{3})+(0×1) = 0\\)\n\\(c_2\\) & \\(c_3\\) = \\((-\\frac{1}{2} \\times -\\frac{1}{3}) + (-\\frac{1}{2} \\times -\\frac{1}{3}) + (1 \\times -\\frac{1}{3}) + ( 0 \\times 1) = 0\\)\n\n\nHelmert contrasts\n\n\n한 그룹과 그 뒤의 그룹들의 평균을 비교하는 방법\nOrthogonal contrasts with equal n\n\\(c_1 = (1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3})\\)\n\\(c_2 = (0, 1, -\\frac{1}{2}, -\\frac{1}{2})\\)\n\\(c_3 = (0, 0, 1, -1)\\)\n\\(c_1\\) & $c_2 = \\((1 \\times 0) + (-\\frac{1}{3} \\times 1) + (-\\frac{1}{3} \\times -\\frac{1}{2}) + (-\\frac{1}{3} \\times -\\frac{1}{2}) = 0\\)\n\\(c_1\\) & $c_3 = \\((1 \\times 0) + (-\\frac{1}{3} \\times 0) + (-\\frac{1}{3} \\times 1) + (-\\frac{1}{3} \\times -1) = 0\\)\n\\(c_2\\) & $c_3 = \\(( 0 \\times 0) + (1 \\times 0) + (-\\frac{1}{2} \\times 1) + (-\\frac{1}{2} \\times -1)\\)\n\n\nRepeated contrasts\n\n\n한 그룹과 바로 다음 그룹을 비교하는 방법\nNon-orthogonal contrasts\n\\(c_1 = (1, -1, 0, 0)\\)\n\\(c_2 = (0, 1, -1, 0)\\)\n\\(c_3 = (0, 0, 1, -1)\\)\n\\(c_1\\) & \\(c_2\\) = \\((1 \\times 0) + (-1 \\times 1) + (0 \\times -1) + (0 \\times 0) = -1\\)\n\\(c_1\\) & \\(c_3\\) = $(1 ) + (-1 ) + (0 ) + (0 ) = 0 $\n\\(c_2\\) & \\(c_3\\) = \\((0 \\times 0) + (1 \\times 0) + (-1 \\times 1) + (0 \\times -1) = -1\\)\n\n\nPolynomial trend contrasts\n\n\n일종의 트랜드(경향성)을 보고자 할 경우 사용\n독립변수 그룹의 순서가 있어야 함\n예) 독립변수 = {10mg, 20mg, 30mg, 40mg} 투약의 양\n독립변수의 그룹간 간격이 일정해야 함 (간격이 다르면 사용할 수 없음)\n그룹내의 관찰값 n이 모두 동일해야 함(=equal n)\nOrthogonal contrasts\n\\(c_{linear} = (-2, -1, 1, 2)\\)\n\\(c_{quadratic} = (1, -1, -1, 1)\\)\n\\(c_{cubic} = (-1, 2, -2, 1)\\)\n\\(c_1\\) & \\(c_2\\) = \\((-2 \\times 1) + (-1 \\times -1) + (1 \\times -1) + (2 \\times 1) = 0\\)\n\\(c_1\\) & \\(c_3\\) = \\((-2 \\times -1) + (-1 \\times 2) + (1 \\times -2) + (2 \\times 1) = 0\\)\n\\(c_2\\) & \\(c_3\\) = \\((1 \\times -1) + (-1 \\times 2) + (-1 \\times -2) + (1 \\times 1) = 0\\)\n\n간단하게 정리해 봤습니다. 이제 Jamovi를 통해 실습을 해보겠습니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#brand-contrasts를-실습해-보자",
    "href": "chapter2.html#brand-contrasts를-실습해-보자",
    "title": "2  Contrasts 분석",
    "section": "2.5 Brand contrasts를 실습해 보자",
    "text": "2.5 Brand contrasts를 실습해 보자\n앞서 계속 사용해 오던 동일한 데이터로 Jamovi에서 brand contrasts를 실습해 보겠습니다. 실습은 유투브를 이용해서 보실 것을 권해드립니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter2.html#t-test와-anova의-전제조건",
    "href": "chapter2.html#t-test와-anova의-전제조건",
    "title": "2  Contrasts 분석",
    "section": "2.6 t-test와 ANOVA의 전제조건",
    "text": "2.6 t-test와 ANOVA의 전제조건\n\n2.6.1 정규성(Normality)\n보통의 통계학 책이나 수업에서는 이런 내용을 t-test나 ANOVA를 배우기 전에 먼저 가르칩니다. 문제는 이 테스트가 무엇인지도 모르는 상황에서 전제조건 혹은 Assumption을 이야기하기 시작하면 도저히 통계를 따라가기가 어려워집니다. 물론 통계를 전공하는 분들이나 정통 통계를 하시는 분들에게는 정말 중요한 부분입니다. 하지만 우리처럼 통계 초보이면서 통알못이라면 정말 이건 외계어 중의 외계어가 될 것입니다. 그래서 저는 어느 정도 두 테스트를 다 공부한 후에 이 전제조건에 대해 설명합니다.\n전제조건이란 쉽게 말해 우리가 t-test나 ANOVA를 하기 위해서 우리의 데이터가 혹은 변수가 당연히 가지고 있어야 하는 특성입니다. 이러한 특성이 담보되지 않는다면 원칙적으로는 이러한 테스트를 할 수 없습니다. 사실 문제는 거의 대부분의 경우 데이터나 변수가 이러한 전제조건을 모두 완벽하게 갖추고 있는 경우가 많지 않다는 것입니다. 일단 하나씩 알아보겠습니다. 여기서는 중요한 몇 가지 중심으로 알아보겠습니다.\n\n정규성 (Normality)\n\n\n정규성이란 데이터가 얼마나 정규분포처럼 생겼는가를 의미합니다.\n다른 말로 정규분포를 잘 따른다고 표현하기도 합니다.\n그렇다면, 정규분포를 잘 따른다는 것은 무슨 뜻일까요?\n\n평균값을 기준으로 값들이 퍼져 있는 확률이 정규분포를 따른다는 뜻입니다.\n즉, 평균값을 기준으로 \\(\\pm1 \\times SD\\)(표준편차)에 약 68.2%의 데이터가 퍼져 있고\n평균값을 기준으로 \\(\\pm2 \\times SD\\)(표준편차)에 약 95.4%의 데이터가 퍼져 있고\n평균값을 기준으로 \\(\\pm3 \\times SD\\)(표준편차)에 약 99.7%의 데이터가 퍼져 있다는 의미가 됩니다.\n\n\n그런데 이러한 분포를 어떻게 확인할 수 있을까요?\n변수의 정규성을 테스트 하는 방법은 대표적으로 다음의 두 가지가 있습니다. - Shapiro-Wilk Test: Jamovi 에 탑재 (다만 샘플사이즈가 클 경우 테스트하지 않음) - Kolmogorov–Smirnov test: Jamovi 에 탑재되어 있지 않음 - 위의 두 테스트 모두 만약 p-value가 유의하다면 (0.05보다 작을 경우) normal 하지 않다는 의미입니다. - 그러므로 정규성 테스트를 통과하려면 유의하지 않아야 합니다.\n문제는 앞서 이야기 했듯이 대부분의 경우 정규성이 완벽하게 확보되는 경우가 드물다는 것입니다. 테스트 결과도 중요하지만 사실 테스트 이전에 히스토그램과 같은 그래프를 그려보는 것이 중요합니다. 너무 심각하게 이상한 분포를 보인다면 고민이 됩니다. 가끔 어떤 분들은 중심극한 정리를 이야기 하면서 n=30이상이면 문제가 없다고 말하긴 하는데 논리적으로 좀 이상한 이야기입니다. 사실 중심극한 정리 조차도 샘플의 사이즈가 커지면 문제가 없다는 의미가 아니라 샘플의 개수가 많아져야 한다는 개념인데 무조건 n=30 이상이면 문제가 없다는 식의 접근은 위험합니다.\n\n왜도(skewness)-비대칭도\n\n왜도란 비대칭도를 의미합니다. 좌측이든 우측이든 꼬리가 긴 경우 문제가 됩니다. 아래의 Figure 2.2 를 보면 첫 번째 Figure 2.2 (a) 는 꼬리가 우측으로 길게 늘어져 있습니다. 이 경우에는 median이 mean 보다 큰 상황이며 왜도는 양수가 됩니다. 일반적으로 어느 한 산업 내의 기업들의 매출 데이터를 보면 이런 경우가 많습니다. 예를 들어 미국의 레스토랑 상장기업의 매출 데이터를 모아보면 이런 형태를 보입니다. 왜냐하면 맥도날드, KFC 등과 같은 몇 개의 대규모 기업이 우측 끝 부분에 위치하기 때문입니다.\n\n\n\n\n\n\n\n(a) right-skewness\n\n\n\n\n\n\n\n(b) left-skewness\n\n\n\n\n\n\n\n(c) normal\n\n\n\n\nFigure 2.2: 왜도 예제\n\n\n반면에 Figure 2.2 (b) 를 보면 꼬리가 좌측에 길게 늘어져 있습니다. 이 경우를 left-skew 하다고 표현하는데, median이 mean 보다 작은 경우이며 왜도는 음수를 나타냅니다. 마지막으로 정규성을 나타내는 경우는 Figure 2.2 (c) 입니다. 좌우의 대칭이 잘 이루어진 모습입니다.\n\n첨도(kurtosis)\n\n첨도란 데이터의 분포가 뾰족한 정도를 의미합니다. 분포의 중간이 뾰족한 경우 (Figure 2.3 좌측) 첨도값은 0보다 크고, 분포의 중간이 평평한 경우 (Figure 2.3 우측) 첨도값은 0보다 작아집니다. 만약 정규분포를 따른다면 첨도값은 0을 나타내게 됩니다.\n\n\n\nFigure 2.3: 첨도 예제\n\n\n\n\n2.6.2 분산의 동질성\n분산의 동질성이란 분산(variance)가 집단별로 동일하다는 뜻으로 영어로는 homogeneity of variance라고 합니다. t-test나 ANOVA에서 가장 중요한 것이 바로 이 분산의 동질성인데, 이를 등분산성이라고 합니다. 등분산 가정이 깨질 경우 비교의 기준이 되는 표준편차 (혹은 분산)을 다시 생각해봐야 합니다. 분산의 동질성을 테스트하는 것이 바로 test for Homogeneity of Variances 혹은 Levene’s test라고 합니다. 이 테스트에서 p-value가 0.05보다 작아 유의할 경우, 이는 등분산 가정이 깨진 것을 의미합니다. 왜냐하면 유의하다는 것은 분산이 다르다는 의미이기 때문입니다.\n문제는 이 등분산 가정이 깨질 경우입니다. 문제는 이론과 현실이 상당히 괴리감이 있다는 점입니다. 많은 경우 현실적인 리서치에서는 아주 심각한 수준의 문제가 아닌 한 적당히 넘어가는 경우가 많습니다. 사실 기준이 무엇이냐고 묻는 다면 답하기 어렵습니다. 분야마다 다르기 때문입니다. 예를 들면, 일반적으로 회계 데이터의 경우 대부분 변수가 양쪽으로 꼬리가 길게 늘어지는 경우가 많습니다. 이때 회계분야의 세계적인 저널들을 보면 자연스럽게 Winsorizing이란 것을 합니다. 찰스 윈저라는 전직 엔지니어였다가 생물통계학자로 이름을 날린 분이라고 합니다. 이 방법은 쉽게 말해 양쪽의 길게 늘어진 꼬리를 강제로 말아 올리는 방법입니다. 그런데, 재미있는 것은 같은 데이터라 하더라도 재무 분야에서는 상위 혹은 하위 5% 혹은 10%의 데이터를 trimming 하기도 합니다. Trim 이라는 것은 쉽게 말해 잘라서 버리는 것이지요. 이렇게 하는 이유는 우리가 사용하는 분석은 모두 평균과 표준편차를 이용하는 것인데, 이렇게 꼬리가 길어지는 변수의 경우 평균과 표준편차가 양쪽의 길게 늘어진 몇 개의 데이터로 인해 심각한 영향을 받기 때문입니다. 즉, 양쪽으로 길게 늘어진 데이터를 기본적으로 Outlier로 취급하는 것입니다.\n그렇다면, 이러한 데이터를 Outlier로 결정하고 지우거나 (trimming) 혹은 말아 올리는 Winsorizing을 하는 것은 언제나 옳을까요? 이게 결정이 쉽지 않습니다. 다른 예를 들어보겠습니다. 미국의 상장기업 회계 데이터 중에서 레스토랑 기업의 매출(sales)를 변수로 끌어와서 들여다보면, 우측으로 길게 늘어진 모습을 볼 수 있습니다. 이러한 현상은 사실 매우 흔한 경우입니다. 만약 우리가 위의 예를 따라 잘라버리거나 말아 올리면 되는 것일까요? 문제는 도대체 누가 이 끝에 있어서 꼬리가 길어졌는지 자세히 보아야 한다는 점입니다. 이 데이터들은 대부분 맥도날드나 KFC 등과 같은 메가 사이즈의 외식기업들입니다. 만약 우리가 변수의 Outlier라는 명분으로 이들을 지우고 혹은 말아 올리고 분석을 하면 어떤 결과가 나올까요? 우리는 분명 레스토랑 산업의 상장기업을 분석했다고 하지만 결론적으로 레스토랑 기업의 대표주자인 맥도날드와 같은 대표 기업을 날려버리고 분석을 한 것입니다. 그렇다면 분석결과가 레스토랑 기업의 대표성을 여전히 지니고 있을까요? 아마도 아닐 것입니다. 따라서 어떠한 절대적 기준은 없습니다. 특히, 사회과학 데이터에서 Outlier를 함부로 결정하는 것은 매우 위험하다는 것이 제 생각입니다. 예를 들어 가장 흔하게 사용하는 Cook’s distance라는 Outlier Detection 방법은 실험 데이터에서는 유효하지만, 사회과학 데이터에서는 그렇게 보기 어렵습니다. 왜냐하면, 실험 데이터란 모든 조건을 동일하게 맞춰 놓은 상태에서 실험하여 얻은 것이므로 비정상적으로 나타나는 값은 Outlier라고 볼 수 있습니다. 그러나 맥도날드의 매출과 같은 경우는 그렇게 동일하게 판단하기 어렵습니다.\n\n\n2.6.3 등분산 가정이 깨질 경우 대안\n등분산 가정이 깨졌다면 대안이 있긴 합니다. 다음은 그 대안을 정리한 것입니다.\n\n등분산 가정이 깨진 경우 t-test의 대안\n\n\nWelch test와 같은 대체 방법을 사용\n경우에 따라서는 non-parametric test인 Mann-Whitney U test를 사용\n\n\n등분산 가정이 깨진 경우 ANOVA의 대안\n\n\nWelch test와 같은 대체 방법 사용 가능\nKruskal-Wallis와 같은 non-parametric test 사용 (단, One-way ANOVA 대용)\n\n위에서 non-parametric test라는 것은 쉽게 말해 파라미터를 사용하지 않는 테스트란 뜻입니다. 여기서 파라미터는 대표적으로 평균이나 표준편차 같은 것을 의미합니다. 즉, 평균이나 표준편차와 같은 것을 사용하지 않는 분석방법이라는 뜻입니다. 어떤 학생들은 그렇다면 차라리 아예 t-test나 ANOVA를 하지 않고 이러한 non-parametric test를 하면 되지 않느냐고 질문하기도 하는데, 이는 매우 위험한 발상입니다. 이러한 방법은 쉽게 말해 대체 방법이지 우선적인 방법이 아닙니다. 검증능력이라는 점에 비추어 본다면 기존의 parametric test가 더 좋기 때문입니다. 보통 이런 non-parametric test는 데이터의 사이즈가 어쩔 수 없이 너무 작은 경우에 사용합니다. 예를 들어 희귀병이나 장애와 관련된 데이터의 경우 수집 가능한 데이터의 사이즈가 매우 작습니다. 실제로 10개 내외인 경우가 많습니다. 이런 경우는 데이터의 사이즈로 인해 사실상 평균이나 표준편차가 전혀 의미를 가질 수 없기 때문에 non-parametric test를 사용하는 것입니다. 이러한 경우가 아니라면 굳이 사용할 이유가 없습니다.\n마지막으로 다른 방법이 있다면 변수의 분포를 조정하는 방법이 있습니다. 일반적으로 사용되는 몇 가지 방법이 있는데, 다음과 같습니다.\n\n데이터의 normalization: 변수의 값을 그 변수의 (최대값 - 최소값)으로 나누는 방법\n데이터의 standardization: 변수의 평균값을 빼고 표준편차로 나누는 방법\n데이터의 log-transformation: 보통 우측으로 꼬리가 긴 경우에 사용하는 방법으로 변수에 자연 log를 붙이는 방법\n\n위의 방법을 사용할 경우 변수가 달라지는 것 아니냐는 의문을 가질 수도 있지만 그렇지 않습니다. 다만 결과를 해석할 때 유의해야 합니다. 이와 관련해서는 뒤에 등장하는 회귀분석에서 보다 자세히 알아보겠습니다.\n\n\n2.6.4 독립성\n마지막으로 독립성에 대해 알아보겠습니다.\n이는 사실 샘플 즉 표본을 모으는 방법과 많은 관련이 있습니다. 예를 들어 설문조사를 해서 표본을 모으고 이를 분석할 경우 어떻게 표본을 모았느냐는 매우 중요한 문제입니다. 예를 들어 설문조사를 주변의 아는 지인들에게만 하는 경우에는 모집된 표본이 모집단의 특성을 대표하지 못하는 상황이 나타납니다. 대표적으로 대학원생들이 설문조사를 할 때, 주변의 대학원생들에게 설문조사를 많이 요구합니다. 결국 데이터를 분석해 보면 교육정도가 일반적인 모집단의 수준에 비해 너무 높게 나타나는 경우를 봅니다. 사실 이렇게 되면 표본 자체가 편향(biased)되어 있다고 볼 수 있어 연구결과에 대한 의문을 제기할 수 있습니다. 또 다른 경우는 특히나 문제가 되는데, 설문조사가 어려워서 동일한 사람에게 설문을 두 개 혹은 세 개씩 해달라고 하는 경우입니다. 아무리 다르게 설문에 응답한다고 해도 이미 이러한 데이터는 객관성을 잃었을 뿐만 아니라, 한 개인이 여러 응답을 하여, 응답 간에 상당한 상관관계가 발생하여 분석 시에 심각한 문제가 발생합니다. 그래서 설문조사를 특정한 특징이 있는 집단에만 할 경우 문제가 되는 것입니다. 표본은 모집단의 특성을 충분히 잘 대표할 수 있어야 하는데, 이러한 조사는 데이터 자체가 이미 편향되어 결과에 문제가 생깁니다. 과거에 가장 문제가 된 경우가 바로 약의 효능검증에 관련된 연구들이었습니다. 심각하게는 인간의 목숨과 관련된 연구임에도 이러한 연구를 할 때, 투약 그룹과 비투약 그룹에 심각한 편차를 두고 연구를 한 경우가 있었습니다. 예를 들어 투약 그룹에는 젊고 상대적으로 건강한 사람들을 넣고, 비투약 그룹에 노약자 혹은 병이 심각하게 진전된 사람들을 넣음으로써 투약 효과를 비정상적으로 확대한 경우입니다. 그래서 최근에 지속적으로 등장하는 이슈가 바로 reproducible research입니다. 출판된 논문의 프로토콜을 따라할 경우 동일한 결과가 나와야 하는 것을 의미합니다. 이러한 것은 일종의 연구윤리와도 연계되어 있어 매우 중요한 이슈입니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#repeated-measure-anova란-무엇인가",
    "href": "chapter3.html#repeated-measure-anova란-무엇인가",
    "title": "3  RM ANOVA",
    "section": "3.1 Repeated Measure ANOVA란 무엇인가?",
    "text": "3.1 Repeated Measure ANOVA란 무엇인가?\n\n3.1.1 반복측정 분산분석\n앞서 우리는 일원배치 분산분석, 이원배치 분산분석 그리고 contrasts 분석까지 꽤 다양한 분석방법을 공부했습니다. 이정도 했으면 그만 나올 법도 한데, 뭔가 새로운 게 또 등장합니다. 사실, 우리나라에서는 그다지 많이 배우는 방법은 아닙니다. 문제는 이 방법을 사용한다면 더 좋았을 경우를 워낙 많이 봐서 제가 꽤 안타까워 굳이 한 가지 더 추가하여 강의를 만들었습니다. 반복측정 분산분석이란 동일한 대상에게 반복하여 측정한 후 데이터를 만들 경우에 하는 분산분석 방법입니다. 예를 들어보겠습니다.\n\n투약 효과 확인을 위해 남녀 25명씩 총 4회 콜레스테롤 레벨 측정\n운동 효과 측정을 위해 남녀 3명씩 6명을 총 3회에 걸쳐 운동 레벨 측정 (Figure 3.1)\n\n\n\n\nFigure 3.1: 반복측정 분산분석의 예제\n\n\n동일한 사람에게 약을 먹이고 총 4회에 걸쳐 그 효과를 측정하는 것은 결국 약의 시간에 따른 효과를 볼 수 있는 매우 좋은 방법입니다. 비슷하게 운동효과를 측정하기 위해 3회에 걸쳐 그 변화를 보는 것은 사실 상당히 자연스럽고 당연한 것처럼 보입니다. 그렇다면 왜 이 경우에 기존에 우리가 알고 있던 일원배치 혹은 이원배치 분산분석과 같은 방법을 쓰면 안 되는 것일까요? 위의 두 번째 예제(Figure 3.1)를 사용하여 설명해 보겠습니다.\n\n\nTable 3.1: 반복측정 분산분석 예제\n\n\nID\n운동전\n3개월 후\n6개월 후\n개인별 평균\n\n\n\n\n1\n45\n50\n55\n50\n\n\n2\n42\n42\n45\n43\n\n\n3\n36\n41\n43\n40\n\n\n4\n39\n35\n40\n38\n\n\n5\n51\n55\n59\n55\n\n\n6\n44\n49\n56\n49.7\n\n\n기간별 평균\n42.8\n45.3\n49.7\n전체 평균45.9\n\n\n\n\nTable 3.1 을 보면, 운동전 6명의 평균은 42.8, 3개월 후는 45.3, 6개월 후는 49.7입니다. 지속적으로 운동레벨이 증가한 것이 보입니다. 전체 평균은 45.9였습니다. One-way ANOVA를 적용해보면, 이 세 그룹의 평균값의 차이가 우리가 원하는 Between Variance가 됩니다. 정확하게는 시간(Time)에 따른 차이가 될 것입니다. 그리고 Within Variance는 각 세 개의 그룹 내 분산이므로 세로로 계산된 분산이 되어야 합니다. 문제는 이 경우 세 개의 그룹의 Within Variance가 서로 간에 상관관계가 있다는 점입니다. 예를 들면 첫 번째 사람 (ID 1)의 경우 운동전에 45, 3개월 후에 50, 6개월 후에 55가 됩니다. 이 세 개의 값은 각각 다른 세 그룹의 Within Variance를 계산할 때 사용되지만 문제는 한 사람의 운동 레벨 결과라는 점이 문제입니다. 이 첫 번째 사람의 개인 평균은 50이면서 동일한 사람이므로 이 세 값 45, 50, 55는 강력한 상관관계가 있을 수밖에 없습니다. 이러한 상관관계가 모든 6명 각각에 발생하므로 우리가 기존의 방법으로 Within Variance를 계산할 경우 이 값에 개인 별 correlation으로 인해 이 값이 비정상적으로 커지게 됩니다. 가끔 왜 커지냐고 묻는 분들이 계시는데, 이를 설명하려면 수학적인 증명 비슷한 것을 해야 하고 제 능력 밖이기도 해서 여기서는 그냥 그렇다고 일단 이해하고 넘어가주실 것을 부탁드립니다. 정확히 왜 커지는지 알고 싶으시다면 대학원 과정의 Mathematical statistics 를 수강하실 것을 권합니다.\n그렇다면, Within Variance가 비정상적으로 커지는 것이 왜 문제일까요? 혹시 다른 방법은 없을까요? 여기서 어떤 분들은 Two-way ANOVA를 떠올리실 수도 있을 것입니다. 맞습니다. 하지만 또 다른 문제가 발생합니다. 여기서 이원배치 분산분석을 사용한다는 것은 개인을 하나의 그룹으로 간주하고 추가적인 변수로 ID를 넣어서 보는 것입니다. 이 경우 위의 데이터는 \\(3 \\times 6\\) 데이터로 바뀌는데 각 셀에 단 하나의 값만 존재합니다. 이렇게 되면 평균과 분산을 구할 수 없으므로 분산분석이 불가합니다. 그렇다면 위의 예제를 일원배치 분산분석으로 분석할 때 문제는 무엇일까요? 바로 F-value가 문제입니다.\n\\[ \\text{F-value} = \\frac{\\text{Between Variance}}{\\text{Within Variance}}\\]\n이미 앞서 반복적으로 이야기 했듯이 F-value는 Between Variance와 Within Variance의 비율입니다. 만약 Within Variance가 비정상적으로 커졌다면, 이는 F-value의 값이 비정상적으로 작아졌다는 것을 의미합니다. 그러므로 F-value가 비정상적으로 작아졌다면 원래는 유의할 수도 있는 p-value가 유의하지 않게 될 수도 있다는 의미가 됩니다. 그러므로 우리는 이 문제를 해결해야 하고 이를 해결하는 방법이 바로 반복측정 분산분석입니다. 반복측정 분산분석의 시스템적인 개념은 아래의 그림과 같습니다.\n\n\n\n\n\n\n\n(a) 일원배치 분산분석\n\n\n\n\n\n\n\n(b) 반복측정 분산분석\n\n\n\n\nFigure 3.2: 일원배치 vs. 반복측정 분산분석의 SS 구조비교\n\n\nFigure 3.2 를 보면 앞에서 배운 일원배치 분산분석은 \\(SS_{Total}\\)을 \\(SS_{Between}\\)과 \\(SS_{Within}\\)으로 나누었다면, 반복측정 분산분석은 조금 다릅니다. 일단 \\(SS_{Total}\\)을 먼저 \\(SS_{Condition}\\)으로 나누는데요. 이 \\(SS_{Condition}\\)은 일원배치 분산분석의 \\(SS_{Between}\\)과 동일합니다. 다만 여기서는 시간의 변화에 따른 차이이기 때문에 일종의 \\(SS_{Time}\\)이라고 볼 수 있습니다. 그리고 일원배치 분산분석의 \\(SS_{Within}\\) 대신 반복측정 분산분석에서는 \\(SS_{Within}\\)이 Within-groups Variance가 되는데, 이는 다시 둘로 쪼개집니다. 먼저 \\(SS_{Subject}\\)는 위에서 한 사람을 여러 번 측정해서 나타나는 Variance를 의미합니다. 즉, 이 Variance가 바로 비정상적으로 커진 분산입니다. 그리고 일원배치 분산분석의 \\(SS_{Within}\\) 역할을 하는 것은 두 번째에 있는 \\(SS_{Error}\\)입니다. 이것이 반복측정 분산분석에서 비교기준이 되는 분산입니다. 그렇다면 이제 반복측정 분산분석의 F-value에 대해서 알아보겠습니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#rm-anova의-f-value를-계산해-보자",
    "href": "chapter3.html#rm-anova의-f-value를-계산해-보자",
    "title": "3  RM ANOVA",
    "section": "3.2 RM ANOVA의 F-value를 계산해 보자",
    "text": "3.2 RM ANOVA의 F-value를 계산해 보자\n그러면 이제 앞의 예제를 이용해서 반복측정 분산분석의 F-value를 계산해 보겠습니다. 앞의 데이터를 다시 가져와 보겠습니다.\n\n\nTable 3.2: 반복측정 분산분석 예제\n\n\nID\n운동전\n3개월 후\n6개월 후\n개인별 평균\n\n\n\n\n1\n45\n50\n55\n50\n\n\n2\n42\n42\n45\n43\n\n\n3\n36\n41\n43\n40\n\n\n4\n39\n35\n40\n38\n\n\n5\n51\n55\n59\n55\n\n\n6\n44\n49\n56\n49.7\n\n\n기간별 평균\n42.8\n45.3\n49.7\n전체 평균45.9\n\n\n\n\n가장 먼저 \\(SS_{Between}\\) 혹은 \\(SS_{Condition}\\)을 계산해 보겠습니다. 여기서는 편의상 이름을 \\(SS_{Time}\\)으로 하겠습니다. 계산 방법은 일원배치 분산분석의 \\(SS_{Between}\\)을 계산하는 방법과 동일합니다. 여기서 우리가 계산하고자 하는 것은 세 개의 시간 그룹들 간의 차이입니다. 그러므로 각 그룹의 평균값으로부터 전체평균값의 차이를 이용하여 분산을 계산하면 됩니다. 먼저 분산의 윗부분(분자부분)을 먼저 계산해 보겠습니다.\n\\[SS_{Time} = 6 \\times (42.8 - 45.9)^2 + 6 \\times (45.3 - 45.9)^2 + 6 \\times (49.7 - 45.9)^2 = 143.44\\]\n분산의 아랫부분(분모부분)은 df로 앞에서 살펴본 내용과 동일합니다. \\(SS_{Time}\\)의 df는 다음과 같이 계산됩니다.\n\\[df = k - 1 = 3 - 1 = 2\\]\n여기서 k는 그룹의 개수로 앞에서 공부한 일원배치 분산분석과 동일합니다.\n다음으로 Within-groups Variance를 구해 보겠습니다. 이 분산은 일원배치 분산분석의 \\(SS_{Within}\\)과 동일하므로 개별 값에서 해당 값이 속한 그룹의 평균을 빼서 제곱하여 합치면 됩니다. 계산 방법은 다음과 같습니다.\n\\[\\begin{matrix}\nSS_{Within} &=& (45 - 42.8)^2 + (42 - 42.8)^2 + (36 - 42.8)^2 + \\cdots \\\\\n            &=& \\vdots \\\\\n            &=& \\cdots + (40 - 49.7)^2 + (59 - 49.7)^2 + (56 - 49.7)^2 \\\\\n            &=& 715.5\n\\end{matrix}\\]\ndf 역시 동일한 방법으로 계산됩니다.\n\\[df = N - k = 18 - 3 = 15\\]\n여기까지는 일원배치 분산분석과 동일합니다. 이제 우리는 이 Within-groups Variance를 Subject Variance와 Error Variance로 분리해야 합니다. 기본적인 전략은 Subject Variance를 구해서 이 값을 앞의 Within Variance에서 빼는 방법을 사용할 것입니다. Subject Variance란 개인별 correlation으로 인해 방생한 분산이라고 이야기 했습니다. 이는 다른 말로 하자면 각 개인을 그룹으로 하는 분산을 구하면 된다는 의미가 됩니다. 왜냐하면 개인별로 평균값이 존재하므로 이를 이용해 분산을 구하면 되기 때문입니다. 따라서 Table 3.2 에서 가로방향 즉 행(row)방향으로 계산된 개인별 평균값을 그룹평균으로 하는 분산을 구하면 됩니다. 개인별 평균값이 전체평균에서 얼마나 멀어져 있는지를 계산하는 분산이라고 보면 됩니다. 계산방법은 아래와 같습니다.\n\\[\\begin{matrix}\nSS_{Subject} &=& 3 \\times (50 - 45.9)^2 + 3 \\times (43 - 45.9)^2 \\\\\n             &=& 3 \\times (40 - 45.9)^2 + 3 \\times (38 - 45.9)^2 \\\\\n             &=& 3 \\times (55 - 45.9)^2 + 3 \\times (49.7 - 45.9)^2 \\\\\n             &=& 658.3\n\\end{matrix}\\]\n\\[ df = n - 1 = 6 - 1 = 5\\]\n여기서 n은 세 그룹 내의 샘플의 개수를 의미합니다. 각 그룹 내의 샘플의 개수는 모두 6이므로 df는 5가 됩니다. 그러면 이제 위에서 계산된 것들을 이용하여 \\(SS_{Error}\\)를 계산해 보겠습니다.\n\\[\\begin{matrix}\nSS_{Error} &=& SS_{Within} - SS_{Subject} \\\\\n           &=& 715.5 - 658.3 \\\\\n           &=& 57.2\n\\end{matrix}\\]\n\\[df = (n-1) \\times (k-1) = 5 \\times 2 = 10\\]\n사실 df도 \\(SS_{Witin}\\)의 df에서 \\(SS_{Subject}\\)의 df를 빼도 동일하게 10이 됩니다. 그렇다면 이제 ANOVA 테이블을 정리해 보겠습니다.\n\n\nTable 3.3: 일원배치 분산분석 결과표\n\n\nSource\nSS\ndf\nMS\nF-value\np-value\n\n\n\n\nBetween\n143.44\n2\n71.72\n1.504\n0.254\n\n\nWithin\n715.5\n15\n47.7\n\n\n\n\nTotal\n858.83\n17\n\n\n\n\n\n\n\nTable 3.3 는 위의 데이터를 일원배치 분산분석으로 분석한 결과표입니다. 우리가 계산한 내용을 정리한 것입니다. 결론적으로 위의 데이터를 일원배치 분산분석으로 분석할 경우 유의하지 않은 결과가 나타납니다. 하지만 이는 Within Variance가 비정상적으로 커졌기 때문입니다. 이 결과를 반복측정 분산분석의 결과표로 다시 정리해 보겠습니다.\n\n\nTable 3.4: 반복측정 분산분석 결과표\n\n\nSource\nSS\ndf\nMS\nF-value\np-value\n\n\n\n\nTime\n143.44\n2\n71.72\n12.538\n0.002\n\n\nWithin-groups\n715.5\n15\n47.7\n\n\n\n\nSubject\n658.3\n5\n131.66\n23.017\n0.0002\n\n\nError\n57.2\n10\n5.72\n\n\n\n\nTotal\n858.83\n17\n\n\n\n\n\n\n\nTable 3.4 는 반복측정 분산분석의 결과표입니다. 참고를 위해 Within-groups Variance 행(row)을 추가했습니다. \\(MS_{Time}\\)인 71.72를 \\(MS_{Error}\\)인 5.72로 나눈 것이 F-value 12.538이 됩니다. 이때의 \\(df_1\\)은 2, \\(df_2\\)는 10이 되어 p-value는 0.002로 유의하게 됩니다. 그러므로 시간이 지남에 따라 운동레벨은 유의한 변화를 보이고 있다고 결론내릴 수 있습니다. 참고로 \\(MS_{subject}\\)인 131.66을 \\(MS_{Error}\\)인 5.72로 나눈 것이 F-value 23.017입니다. 이 경우 p-value가 0.0002로 매우 유의하게 나타나는데 이는 실험에 참가한 사람별로 분명한 평균적인 운동능력의 차이가 있다는 것을 알 수 있습니다.\n이제 가장 어려운 부분은 조금 넘어선 것 같네요. 조금만 더 힘을 내면 끝이 보일겁니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#rm-anova의-구형성-가정",
    "href": "chapter3.html#rm-anova의-구형성-가정",
    "title": "3  RM ANOVA",
    "section": "3.3 RM ANOVA의 구형성 가정",
    "text": "3.3 RM ANOVA의 구형성 가정\n\n3.3.1 구형성 가정이란?\nRM ANOVA (반복측정 분산분석)에 등장하는 특별한 가정(전제조건)이 바로 구형성 가정입니다. 사실 저도 이름이 왜 구형성 가정인지 조금 의아하긴 합니다. 뒤에 등장할 요인분석의 구형성 가정과 헷갈리지 마시길 바랍니다. 앞서 이야기 했듯 각 subject가 몇 차례 반복 측정되어 ANOVA의 전제조건인 독립성 가정이 이미 깨졌다는 것이 문제입니다. 그래서 독립성 가정 대신 반복측정 분산분석에서는 구형성(Sphericity)가정이 대신 등장합니다. 구형성(Sphericity) 가정이란 반복 측정된 자료들의 시차(time)에 따른 분산이 동일하다는 전제를 의미합니다. 이를 확인하는 방법은 아래와 같습니다.\n\nMouchly의 단위행렬 검정을 통한 확인 (P값이 0.05 보다 커야 함)\nGreenhouse-Geisser \\(\\epsilon\\) 과 Huynh-Feidt \\(\\epsilon\\) 은 1에 가까울수록 구형성 가정에 타당\n\n만약, 구형성 가정을 만족하게 되면 일반적인 결과 표를 확인하고, 만족하지 못하면 Greenhouse-Geisser 등의 방법으로 수정된 결과를 이용해야 합니다. 좀 복잡하지요? 보다 자세한 설명을 하자면 다음과 같습니다. 구형성 가정이란 데이터에 포함된 개별 subject들이 어느 정도의 동질성을 확보했는지 확인하는 방법입니다. 예를 들어 만약 매우 병약한 노인과 매우 건장한 청년을 섞어 놓고 신약의 효과를 검정할 경우 개인별 동질성이 매우 낮아 신약의 효과가 개인 간 차이에 의해 잘못된 결과를 나타낼 수 있습니다. 사실 반복측정으로 인해 이미 독립성 가정이 깨졌으므로, 데이터에서 최대한 독립성과 무작위성을 확보하기 위한 조건으로 생각하면 됩니다.\n현재로서는 이정도만 이해하고 가도 충분합니다.\n\n\n3.3.2 RM ANOVA의 데이터 코딩\n사실 앞에서 일원배치 분산분석이나 이원배치 분산분석에서 데이터 코딩을 어떻게 해야 하는지 몇 차례 설명한 적이 있습니다. 문제는 같은 분산분석이어도 반복측정 분산분석은 데이터 코딩 방법이 다르다는 점입니다. 다음의 그림을 보면서 설명하겠습니다.\n\n\n\nFigure 3.3: 반복측정 분산분석의 데이터 코딩\n\n\n앞에서 공부한 일원배치 혹은 이원배치 분산분석이었다면, 종속변수가 한 열(column), 독립변수가 각각 한 열(column)을 차지해야 맞습니다. 그러나 위의 Figure 3.3 에서 보듯 반복측정 분산분석의 경우 하나의 그룹을 한 열(column)로 코딩하고 있습니다. 그러므로 반복측정 분산분석을 이용하여 분석할 경우 기존과 다른 데이터셋을 만들어 분석해야 합니다. 이러한 차이를 모르면 데이터 입력이 안되어 분석이 불가능해집니다. 반드시 유의하여 코딩하시길 바랍니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#rm-anova를-실습해-보자",
    "href": "chapter3.html#rm-anova를-실습해-보자",
    "title": "3  RM ANOVA",
    "section": "3.4 RM ANOVA를 실습해 보자",
    "text": "3.4 RM ANOVA를 실습해 보자\n우리가 위에서 F-value를 계산해 보았던 그 예제를 그대로 Jamovi로 실습을 해 보겠습니다. 사실 데이터의 개수가 너무 작아 현실적으로는 문제가 있지만 우리는 지금 공부용으로 사용하기 때문에 이러한 문제는 일단 제외하고 실습해 보시면 될 것 같습니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#two-way-rm-anova를-알아보자",
    "href": "chapter3.html#two-way-rm-anova를-알아보자",
    "title": "3  RM ANOVA",
    "section": "3.5 Two-way RM ANOVA를 알아보자",
    "text": "3.5 Two-way RM ANOVA를 알아보자\n\n3.5.1 변수의 종류\n그러면 이제 조금 어려운 부분을 시작해 보겠습니다. 굳이 필요하지 않다면 억지로 공부할 필요는 없지만 공부해서 나쁠 것도 없죠. 지금부터는 독립변수가 두 개인 반복측정 분산분석에 대해 알아보겠습니다. 사실 제가 박사공부를 하던 시절만 해도 이 방법은 워낙 복잡해서 사실 이론적으로는 있지만 실제적으로 분석을 하는 경우는 거의 보지 못했던 방법입니다. 아주 단순한 예제만 테스트 해봤던 기억이 있네요. 일단 이원 반복측정 분산분석에서는 중요한 것이 독립변수의 구분입니다. 이원 반복측정 분산분석에는 두 가지의 독립변수가 있습니다.\n\nWithin-subject Variable (개체 내 변수)\n\n\n한 개체에 대해서 두 번 이상 반복하여 측정한 경우\n조건을 바꿔 가면서 동일한 대상에게 여러번 측정을 하면 개체 내 변수로 인식\n\n\nBetween-subject Variable (개체 간 변수)\n\n\n한 개체가 한 변수 내에서 한 그룹에만 해당하는 경우\n동일한 대상에 대해서 여러차례 조건을 바꿔가며 측정하는 것이 아니라 조건이 고정된 경우\n앞서 보았던 일원배치/이원배치 분산분석의 경우와 동일\n\n문제는 독립변수가 두 개일 경우 상황에 따라서 Within-subject variable이 두 개일 수도 있고, 한 개는 Within-subject 다른 한 개는 Between-subject variable일 수 있다는 점입니다. 만약 둘 다 Between-subject variable이라면 이 경우는 반복측정 분산분석이 아닌 앞에서 공부한 이원배치 분산분석입니다.\n\n\n3.5.2 이원 반복측정 분산분석의 종류\n독립변수가 두 개인 경우 다음과 같은 세 가지 종류의 이원 반복측정 분산분석이 있을 수 있습니다.\n\nTwo-way (or Two-factor) Repeated Design\n\n\n두 개의 변수가 모두 Within-subject Variable인 경우를 의미\n20명의 성인을 대상으로 노이즈 레벨(None/Low/Med/High)과 텍스트 이미지(Clear/Blur)에 (4×2) 따라 주어진 메세지를 얼마나 잘 이해했는지 테스트하는 경우\n\n노이즈 변수와 텍스트 이미지 변수 둘 다 Within-subject Variable이 됨\n총 8번에 걸쳐 동일한 사람에게 테스트를 하였기 때문에 Two-way Repeated Design이 됨\n\n\n\nTwo-way (or Two-factor) Mixed Design\n\n\n한 개의 변수는 Within-subject Variable이고 다른 한 개의 변수는 Between-subject Variable인 경우를 의미\n배우자의 직업으로 인해 거주지지를 이동한 30명의 여성을 대상으로 배우자와 같이 자는 날과 그렇지 않은 날에 따라 델타 수면시간을 측정하되, 이들의 애착형태(안정적/두려움/회피)를 추가적인 독립변수로 하여 조사하는 경우\n\nWithin-subject Variable은 배우자 동침 여부, Between-subject Variable은 애착형태\n\n기간별로 나누어 총 3회 수학시험을 보게 한 학생들의 방과후 수업 여부에 따른 수학점수차이 비교\n\nWithin-subject Variable은 3획 각각의 시험, Between-subject Variable은 방과후 수업 여부\n\n\n\nTwo-way (or Two-factor) Nested Design\n\n\n두 개의 변수가 모두 Within-subject Variable이면서 한 변수가 다른 변수에 소속된 경우\n\n서울 4 개의 구(서초구/강남구/노원구/영등포구)내의 랜덤하게 선정된 5개의 초등학교 3학년을 대상으로 수학 실력고사를 시행\n4 개의 구와 5 개의 초등학교 둘 다 Within-subject Variable이며\n5 개의 초등학교는 각 4 개의 구 안에 속해 있음\n여기서 첫 번째 변수인 “구”는 고정된(fixed) 변수이고 두 번째 변수인 5개의 학교는 무작위(random) 선정\n\n\n사실 마지막 경우는 반복측정 분산분석이라기에는 제가 봐도 좀 애매합니다. 다시 보니 사실 Repeated Design이라기 보다는 그냥 Nested Design으로 보는 것이 합리적일 것 같습니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#이원-반복측정-분산분석의-f-value를-계산해-보자",
    "href": "chapter3.html#이원-반복측정-분산분석의-f-value를-계산해-보자",
    "title": "3  RM ANOVA",
    "section": "3.6 이원 반복측정 분산분석의 F-value를 계산해 보자",
    "text": "3.6 이원 반복측정 분산분석의 F-value를 계산해 보자\n\n3.6.1 복습시간\n잠시 복습하는 시간을 가져보겠습니다.\n경우에 따라 이 방법은 생각보다 분산분석을 보다 쉽게 이해하는데 도움이 되기도 하기 때문에 차근차근 보시면 좋습니다. 굳이 새로운 방식으로 복습을 하는 이유는 이원 반복측정 분산분석이 생각보다 계산이 어렵기 때문입니다. 그럼 하나씩 다시 살펴보겠습니다.\n\n일원배치 분산분석 (One-way ANOVA)\n\n\n한 개의 독립변수를 이용해 종속변수의 차이를 보고자 하는 경우\n독립변수 A의 평균값을 [A], 전체 평균값을 [T], 종속변수의 개별 값 \\(Y_{i}\\)를 [Y]라고 표기한 다면,\n\\(SS_{Between} = [A] - [T]\\)이 되는데 여기서 [A] - [T] 가 의미하는 것은 독립변수 A의 그룹별 평균값에서 전체 평균값을 뺀 후에 제곱하여 합한 것이라는 의미입니다. 이러한 방식으로 계속 표현하면,\n\\(SS_{Within} = [Y] - [A]\\)로 표현할 수 있습니다.\n그렇다면 이제 이 둘을 합한 것은 \\(SS_{Total} = SS_{Between} + SS_{Within} =\\) [A] - [T] + [Y] - [A] = [Y] - [T] 가 됩니다.\n\n조금 독특한 방법이지만 전체적인 시스템을 이해하기에 매우 좋은 방법입니다. 중요한 것은 \\(SS_{Total}\\)은 언제나 [Y] - [T]가 되어야 한다는 사실입니다. 이제 조금 더 복습해 보겠습니다.\n\n이원배치 분산분석 (Two-way ANOVA)\n\n\n위와 같이 독립변수 A와 B의 평균값을 각각 [A]와 [B], 두 독립변수가 만드는 교차 셀의 평균값을 [AB], 전체 평균값을 [T], 종속변수의 개별 값 \\(Y_{i}\\)를 [Y]라고 표기한 다면,\n\n\\(SS_{Between\\;A} =\\) [A] – [T]\n\\(SS_{Between\\;B} =\\) [B] – [T]\n\\(SS_{Interaction\\;AB} =\\) [AB] – [A] – [B] + [T]\n\\(SS_{Within} =\\) [Y] – [AB]\n\n\\(\\begin{matrix} SS_{Total} &=& SS_{Between\\;A} + SS_{Between\\;B} + SS_{Interaction\\;AB} + SS_{Within} \\\\ &=& [A] - [T] + [B] - [T] + [AB] - [A] - [B] + [T] + [Y] - [AB] \\\\ &=& [Y] - [T] \\\\ \\end{matrix}\\)\n\n\n일원 반복측정 분산분석 (One-way Repeated Measure ANOVA)\n\n\nWithin-subject variable A의 평균값을 [A], Subject별 평균값을 [S], 전체 평균값을 [T], 종속변수의 개별 값 \\(Y_{i}\\)를 [Y]라고 표기한 다면,\n\n\\(SS_{Time} =\\) [A] – [T]\n\\(SS_{Within-groups} =\\) [Y] – [A]\n\\(SS_{Subject} =\\) [S] - [T]\n\\(SS_{Error} = SS_{Within-groups} - SS_{Subject}\\)\n\\(SS_{Error}\\)를 직접 구해보면, $SS_{Error} = $ [Y] - [S] - [A] + [T]$\n여기서 재미있는 것은 \\(SS_{Error}\\)를 계산하는 방법이 이원배치 분산분석에서 interaction을 계산하는 방식과 동일하다는 것입니다.\n\n\\(\\begin{matrix} SS_{Total} &=& SS_{Time} + SS_{Subject} + SS_{Error} \\\\ &=& [A] - [T] + [S] - [T] + [Y] - [S] - [A] + [T] \\\\ &=& [Y] - [T] \\\\ \\end{matrix}\\)\n\n\n\n3.6.2 이원 반복측정 분산분석의 F-value의 계산\n\nTwo-way (or Two-factor) Repeated Design\n\n\n20명의 성인을 대상으로 노이즈 레벨(None/Low/Med/High)과 텍스트 이미지(Clear/Blur)에 (4×2) 따라 주어진 텍스르를 얼마나 잘 이해했는지 테스트\n노이즈와 텍스트 이미지 둘 다 Within-subject Variable\n데이터 코딩시 주의할 점\n\n전체적으로 (4×2) 디자인\nOne-way/Two-way ANOVA에서는 무조건 종속변수가 1개의 칼럼(column)이었으나,\nOne-way Repeated Measure ANOVA 처럼 종속변수가 1개의 칼럼(column)이 아님\n종속변수의 열(column)의 개수는 (4×2) = 8 개\n\n\n이 경우 코딩 방법은 아래의 Figure 3.4 와 같이 되어야 합니다.\n\n\n\nFigure 3.4: 이원 반복측정 분산분석 데이터 코딩\n\n\n이제 F-value를 계산해 보겠습니다.\n\n\n\nFigure 3.5: 이원 반복측정 분산분석의 F-value\n\n\nFigure 3.5 의 좌측은 20명의 피실험자의 총 8회 텍스트 이해도 점수입니다. Clear/Blur 두 그룹 내에 None/Low/Med/High 네 개의 그룹이 있어 총 8개의 그룹이 됩니다. 노란색으로 표기된 가장 우측 열(column)은 개인별 평균값 [S]이고, 가장 아래의 노란색 행(row)은 두 변수의 교차 셀의 평균값 [AB]입니다. 가장 우측 아래의 초록색 46이 전체 평균값 [T]입니다. 가운데는 개인별로 None/Low/Med/High 네 개의 그룹의 평균값을 정리한 것으로 이는 [AS]로 표기할 수 있겠습니다. 이 표의 가장 아래의 노란색 행(row)은 변수 A의 그룹별 평균값인 [A]가 됩니다. 마지막으로 가장 우측은 개인별로 Clear/Blur 두 그룹의 평균값을 정리한 것으로 [BS]이며, 가장 아래의 노란색 행(row)은 변수 B의 그룹별 평균값인 [B]가 됩니다. 이제 어떻게 계산하는 것인지 표로 정리해 보겠습니다. 다소 복잡해 보일 수 있으니 차근차근 보시길 바랍니다.\n\n\n\nFigure 3.6: 이원 반복측정 분산분산 F-value 계산\n\n\n이제 Figure 3.6 을 보면서 계산하는 방법을 하나씩 알아봅시다. 가장 먼저 계산하는 것이 바로 \\(SS_{Subject}\\)입니다. 이는 개인 당 8 회의 검사 결과를 개인별로 평가한 것의 평균값에서 전체 평균을 빼서 제곱하여 총 \\(a \\times b\\)회 곱하는 것입니다. 왜냐하면 \\(a \\times b = 8\\)이기 때문입니다. 왜 8을 곱해야 하는지 모르시겠다면 앞의 일원배치 분산분석부터 이원배치 분산분석까지 다시 자세히 공부해 보시기 바랍니다. \\(SS_{Subject}\\)의 df는 \\(r - 1\\)로 이 둘을 이용해 \\(MS_{Subject}\\)를 구할 수 있습니다. 여기서 r은 실험 참여자 수인 20명을 의미합니다. 하지만 이 분산값은 우리의 관심사가 아닙니다. 우리의 관심사는 두 개의 독립변수와 이 두 독립변수가 만들어 내는 Interaction의 유의성 여부입니다.\n첫 번째 변수인 Noise의 SS를 구해보면 \\(SS_{Noise} = (b \\times r) \\times ([A] - [T])\\)가 됩니다. 당연한 것이지만 Noise 변수의 그룹별 평균값인 [A]에서 전체 평균값인 [T]를 빼고 난 뒤에 제곱합을 총 \\(b \\times r = 2 \\times 20 = 40\\) 만큼 곱하면 됩니다. 왜냐하면 Figure 3.5 의 가운데 부분을 보면 [A]는 사실 40개의 값을 평균하여 만든 값이기 때문입니다. Noise의 df는 앞에서 본 다른 분산분석과 동일하게 그룹의 개수에서 1을 뺀 \\(a - 1 = 2 - 1 = 1\\)이 됩니다.\n이제 다시 몇 가지 설명이 필요할 것 같네요. 먼저 앞에서 살펴본 일원 반복측정 분산분석에서는 \\(SS_{Error}\\)를 구하기 위해서 쉽게 \\(SS_{Within}\\) 즉 Within-groups의 SS(Sum of Squares)에서 \\(SS_{Subject}\\)를 빼는 방법을 사용했습니다. \\(SS_{Error}\\)의 정확한 계산법은 앞의 복습부분에서 확인한 바 있습니다. 방법은 마치 이원배치 분산분석의 Interaction의 SS를 구하는 방법과 동일했습니다. 이제 \\(MS_{Noise}\\)의 비교대상이 될 \\(SS_{Error}\\)를 구해야 하는데, 이원 반복측정 분산분석에서는 각 SS별로 다른 \\(SS_{Error}\\)를 가지게 됩니다. 이유는 Subject별 영향이 변수별로 다르기 때문입니다. 그래서 여기서는 \\(MS_{Noise}\\)의 비교대상이자 기준이 될 분산을 \\(MS_{N \\times S}\\)로 표기하겠습니다. 위의 Figure 3.6 에서는 Residual(Noise \\(\\times\\) Subject)라고 표기된 부분입니다. \\(SS_{Residual:N \\times S}\\)은 \\(b \\times ([AS] - [A] - [S] + [T])\\)로 계산됩니다. 마치 이원배치 분산분석에서 A와 S의 Interaction을 구하듯이 구하는 것입니다. df 는 \\((a - 1) \\times (r - 1)\\)입니다. 그러므로 첫 번째 변수인 Noise의 F-value는 \\(MS_{Noise} \\div MS_{N \\times S}\\)가 됩니다.\n동일한 방법으로 두 번째 변수인 Image의 F-value를 구하는 방법은 다음과 같습니다\n\\[SS_{Image} = (a \\times r) \\times ([B] - [T])\\]\n\\[ df_{Image} = b - 1\\]\n\\[MS_{Image} = SS_{Image} \\div df_{Image}\\]\n\\[SS_{I \\times S} = a \\times ([BS] - [B] - [S] + [T])\\]\n\\[df_{I \\times S} = (b - 1) \\times (r - 1)\\]\n\\[MS_{I \\times S} = SS_{I \\times S} \\div df_{I \\times S}\\]\n그러면 이제 F-value는 이 두 값을 이용해 구할 수 있습니다.\n\\[F-value_{Image} = MS_{Image} \\div MS_{I \\times S}\\]\n이제 Noise와 Image 두 변수의 Interaction을 구해볼 차례입니다. 두 변수의 Interaction을 구할 때 \\(MS_{N \\times I}\\)는 이원배치 분산분석의 경우와 동일합니다. 다만 이 분산을 나누어줄 기준이될 분산인 \\(MS_{Error}\\)를 따로 구해야하는 것이 좀 복잡하긴 합니다만, 기본적인 방법은 Interaction의 Interaction을 구한다고 생각하고 계산하면 됩니다. 아래의 식을 보면 좀 더 이해하는데 도움이 될 것입니다.\n\\[SS_{N \\times I} = r \\times ([AB] - [A] - [B] + [T])\\]\n\\[df_{N \\times I} = (a - 1) \\times (b - 1)\\]\n\\[MS_{N \\times I} = SS_{N \\times I} \\div df_{N \\times I}\\]\n\\[SS_{N \\times I \\times S} = ([Y] - [AB] - [AS] - [BS] + [A] + [B] + [S] - [T])\\]\n\\[df_{N \\times I \\times S} = (a - 1) \\times (b - 1) \\times (r - 1)\\]\n\\[MS_{N \\times I \\times S} = SS_{N \\times I \\times S} \\div df_{N \\times I \\times S}\\]\n그렇다면 F-value는 다음과 같습니다.\n\\[F-value_{N \\times I} = MS_{N \\times I} \\div MS_{N \\times I \\times S}\\]\n그렇다면 종합적으로 일원 반복측정 분산분석과 Two-way (or Two-factor) Repeated Design이 어떻게 다른지 아래의 그림을 보겠습니다.\n\n\n\n\n\n\n\n(a) One-way RM ANOVA\n\n\n\n\n\n\n\n(b) Two-way Repeated Design\n\n\n\n\nFigure 3.7: 반복측정 분산분석의 비교\n\n\nTwo-way Repeated Design이 되면 \\(SS_{Time}\\)이 두 개의 Main Effect \\(SS_A\\), \\(SS_B\\), \\(SS_{A \\times B}\\)가 됩니다. 이 세 개의 SS는 비교대상이 별도로 하나씩 있는데 이는 Subject의 영향이 각각 다르기 때문입니다. 그래서 \\(SS_{Within-groups}\\)가 다시 쪼개지는데, \\(SS_{Subject}\\)를 제외한 나머지 세 개가 각각 \\(SS_{Error}\\)의 역할을 하게 되는 것입니다.\n\nTwo-way Mixed Design\n\n\n이 경우 한 개의 변수는 Within-subject Variable이고 다른 한 개의 변수는 Between-subject Variable\n우리가 사용할 예제는 기간별로 3회 수학시험을 보게 한 학생들이 방과후 수업에 따라 점수차이가 있는지 비교하고자 합니다.\nWithin-subject Variable은 3회의 시험, Between-subject Variable은 방과후 수업 여부\n데이터는 앞의 t-test 실습 때 사용했던 데이터 입니다.\nKaggle.com에 접속하여 좌측 상단의 검색창에서 independent-t-test-example을 검색해도 찾을 수 있습니다.\n데이터 코딩\n\n걱정할 필요는 없으나 우리가 원하는 포멧은 3회의 시험 점수는 각 별도의 칼럼에, 방과후 수업 여부(Paid 변수)는 yes/no로 한 개의 칼럼에 들어있어야 합니다.\n\n\n문제는 앞의 Two-way Repeated Design과 달리 이 경우에는 한 개의 변수가 Between-subject Variable이므로 SS의 구조가 달라집니다. 먼저 이 구조가 어떻게 다른지 앞의 Two-way Repeated Design과 비교해 보겠습니다.\n\n\n\n\n\n\n\n(a) Two-way Repeated Design\n\n\n\n\n\n\n\n(b) Two-way Mixed Design\n\n\n\n\nFigure 3.8: 반복측정 분산분석의 비교 2\n\n\nFigure 3.8 (b) 에서 보듯이 다른 RM ANOVA와 달리 \\(SS_{Subject}\\)가 따로 없다는 점이 특징입니다. 또한 변수의 효과를 Between-subject Effect와 Within-subject Effect로 나누는 점이 독특하고, 특히 두 변수의 Interaction은 Within-subject Effect에서 처리한다는 점이 재미있습니다. 계산방법은 아래에 정리해 두었습니다.\n\n\n\n\n\n\n\n(a) Between-subject Effect\n\n\n\n\n\n\n\n\n\n(b) Within-subject Effect\n\n\n\n\nFigure 3.9: Two-way Mixed Design의 F-value 계산방법\n\n\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter3.html#two-way-rm-anova를-실습해-보자",
    "href": "chapter3.html#two-way-rm-anova를-실습해-보자",
    "title": "3  RM ANOVA",
    "section": "3.7 Two-way RM ANOVA를 실습해 보자",
    "text": "3.7 Two-way RM ANOVA를 실습해 보자\n우리가 실습할 예제는 두 가지입니다.\n\n3.7.1 예제 1: Two-way (or Two-factor) Repeated Design\n\n20명의 성인을 대상으로 노이즈 레벨(None/Low/Med/High)과 텍스트 이미지(Clear/Blur)에 (4×2) 따라 주어진 텍스르를 얼마나 잘 이해했는지 테스트\n노이즈와 텍스트 이미지 둘 다 Within-subject Variable\n데이터 코딩시 주의점\n\n전체적으로 (4×2) 디자인\n일반 ANOVA에서는 종속변수가 1개의 칼럼(column)이었으나, 여기서는 종속변수의 칼럼(column)수는 (4×2) = 8 개\n데이터\n\n\n\n\n3.7.2 예제 2: Two-way (or Two-factor) Mixed Design\n\n기간별로 3회 수학시험을 보게 한 학생들이 방과후 수업에 따라 점수차이 비교\nWithin-subject Variable은 시험 횟수, Between-subject Variable은 방과후 수업 여부\n데이터는 앞의 t-test 실습 때 사용했던 데이터로 Kaggle.com에 접속하여 좌측 상단의 검색창에서 independent-t-test-example을 검색해도 찾을 수 있음\nGithub 데이터\n데이터 코딩\n\n걱정할 필요는 없으나 우리가 원하는 포멧은 3회의 시험 점수는 각 별도의 칼럼에, 방과후 수업 여부는 yes/no로 한 개의 칼럼에 들어있어야 함\n\n\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter4.html#three-way-anova에-대해-알아보자",
    "href": "chapter4.html#three-way-anova에-대해-알아보자",
    "title": "4  고차원 분산분석",
    "section": "4.1 Three-way ANOVA에 대해 알아보자",
    "text": "4.1 Three-way ANOVA에 대해 알아보자\n\n4.1.1 독립변수가 더 많아진다면?\n이제 분산분석을 다 공부했습니다. 남아있는 의문이 있다면 아마도 독립변수가 3개 이상이라면 어떨까? 라는 생각이 들 수 있습니다. 사실 얼마든지 분석이 가능합니다. 특히나 지금은 컴퓨터의 성능이 좋아져서 계산이 불가능하지 않습니다. 결론적으로 문제는 해석이 매우 어려워진다는 점입니다. 솔직히 3 개 이상의 독립변수를 넣어서 분산분석을 하는 것을 저는 개인적으로 추천하지 않습니다. 가끔 논문에 Three-way ANOVA가 등장하기는 하지만 솔직히 해석도 어렵고 특히나 이를 그래프로 그리기도 어렵습니다. 3D로 그려야 하기 때문인데 이 경우 3D 그래프를 움직이면서 interactive하게 보지 않으면 이해가 어렵기 때문입니다.\n단수한 예로, 만약 독립변수가 3 개라면 Main Effect는 당연히 3 개이고, Two-way interaction은 \\(3 \\times 2 \\div 2 = 3\\)개가 되고 Three-way interaction은 한 개가 됩니다. 여기서 다시 독립변수가 한 개 더 늘어서 4 개가 되면, Main Effect 4개, Two-way interaction \\(4 \\times 3 \\div 2 = 6\\)개가 되고, Three-way interaction \\(4 \\times 3 \\times 2 \\div 6 = 4\\)개, 그리고 Four-way interaction 한 개가 됩니다. 이런 식이 되면 이제 interaction이 많아서 문제이기도 하지만 각 interaction에 대한 해석이 어려워집니다. 그래서 일반적으로는 이원배치 분산분석 이상을 하지 않습니다.\nThree-way ANOVA의 F-value 계산방법은 유투브 강의에 올려놓았습니다만, 그 방법을 여기서 반복 설명하는 것은 큰 의미는 없을 것 같습니다. 어차피 계산이야 컴퓨터와 통계 소프트웨어가 해주니까요. 문제는 테스트 결과를 해석하는 것도 매우 어렵다는 것입니다. 예를 들면 이렇습니다.\n\n\n4.1.2 Three-way ANOVA에서 Two-way interaction의 해석\n\n변수 A와 B의 interaction effect는 다른 변수 C의 모든 그룹(=레벨)의 평균을 전제하고 난 후, 변수 A의 효과가 모든 그룹(=레벨)의 변수 B에서 똑같이 나타나는지 아닌지 확인하는 것을 의미\n변수 A와 C의 interaction effect는 다른 변수 B의 모든 그룹(=레벨)의 평균을 전제하고 난 후, 변수 A의 효과가 모든 그룹(=레벨)의 변수 C에서 똑같이 나타나는지 아닌지 확인하는 것을 의미\n변수 B와 C의 interaction effect는 다른 변수 A의 모든 그룹(=레벨)의 평균을 전제하고 난 후, 변수 B의 효과가 모든 그룹(=레벨)의 변수 C에서 똑같이 나타나는지 아닌지 확인하는 것을 의미\n\n위의 설명이 이해가 되시나요? 이렇게 복잡해지는 이유는 변수가 3개이기 때문입니다. 두 변수의 interaction이지만 나머지 한 변수의 수준이 바뀌면 interaction 자체가 바뀔 수 있기 때문에 기본적으로 나머지 변수에 대해서는 평균을 전제로 합니다. 만약 Three-way가 Four-way로 확장되면 나머지 두 변수의 수준이 모두 평균으로 전제 혹은 가정하고 보는 것입니다. 쉽게 이해되기 어렵습니다. 문제는 또 있습니다.\n\n\n4.1.3 Three-way ANOVA에서 Three-way interaction의 해석\n\n\\(Interaction_{A \\times B}\\)의 효과가 모든 레벨(=그룹)의 변수 C에서 똑같이 나타나는지 확인하는 것을 의미\n\\(Interaction_{A \\times C}\\)의 효과가 모든 레벨(=그룹)의 변수 B에서 똑같이 나타나는지 확인하는 것을 의미\n\\(Interaction_{B \\times C}\\)의 효과가 모든 레벨(=그룹)의 변수 A에서 똑같이 나타나는지 확인하는 것을 의미\n\n게다가 Three-way ANOVA가 되면 3D로 그림을 그리면서 설명해야 하는데, 정확한 의미를 전달하고 설명하려면 단순한 그림이 아니라 움직이는 그래픽이나 아예 영상으로 돌려가면서 보여줘야 합니다. 설명도 어렵지만 보여주기도 쉽지 않습니다.\n\n\n4.1.4 고차원 분산분석에 대한 집착\n사실 통계를 처음 공부하다 보면 좀 더 복잡하고 어려운 방법이 더 좋은 것이라는 착각을 하기도 합니다. 하지만 전혀 그렇지 않습니다. 많은 변수를 투입한다고 하여 좋은 모델이라거나 연구가 되지는 않습니다. 또한, 이 세상의 모든 변수를 다 집어넣어야 하는 것도 아닐 뿐더러 그럴 수도 없습니다. 핵심은 분석의 목적에 맞게 중요한 변수를 중심으로 분석하는 것이 필요합니다.\n통계에는 Parsimonious라는 개념이 있는데 이 개념이 중요합니다. Parsimonious란 가장 단순한 모델 혹은 이론을 바탕으로 최소한의 전제조건과 변수를 이용해 분석할 때, 가장 훌륭한 결과와 해석이 가능하다는 의미입니다. 결과 해석도 못하면서 아무 변수나 때려 박는 것은 무책임할 뿐 아니라 바보입니다. 통계분석의 목적이 학문적 연구일 경우에는 특히 이론을 바탕으로 기존의 연구를 충분히 읽고 이를 이용해 논리적인 가설을 세워 진행해야 합니다. 어떠한 경우에도 통계분석의 목적이 실질적인 이득을 위한 경우라면 parsimonious 원칙은 중요합니다.\nYoutube 바로 가기"
  },
  {
    "objectID": "chapter4.html#three-way-anova를-실습해-보자",
    "href": "chapter4.html#three-way-anova를-실습해-보자",
    "title": "4  고차원 분산분석",
    "section": "4.2 Three-way ANOVA를 실습해 보자",
    "text": "4.2 Three-way ANOVA를 실습해 보자\n\n실습용 데이터: Two-way ANOVA 실습 데이터와 동일\nhttps://www.kaggle.com/ 에 접속하여 좌측 상단의 검색창에 Telco Customer Churn을 검색하여 검색된 최 상단의 것을 클릭\n우측 중간의 Download를 클릭하여 데이터 다운로드\nGithub 다운로드\n\nYoutube 바로 가기"
  }
]